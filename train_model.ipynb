{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Next steps:\n",
    "1. Add a \"master node\" that connects all nodes together, so that message passing works between all nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from EmbedDataset import LigandBinaryDataset\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = LigandBinaryDataset('./data2/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:int(len(dataset) * 0.7)]\n",
    "val_dataset = dataset[int(len(dataset) * 0.7):int(len(dataset) * 0.85)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.85):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=16)\n",
    "val_dl = DataLoader(val_dataset, batch_size=16)\n",
    "test_dl = DataLoader(test_dataset, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from LigandGNNV2 import LigandGNNV2\n",
    "from LigandGNNV1 import LigandGNNV1\n",
    "from sagn.models import SAGN\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# model = LigandGNNV1(dataset.num_node_features, 1).to(device)\n",
    "model = LigandGNNV2(128, 42).to(device)\n",
    "# model = SAGN(in_feats=1070, hidden=1024, out_feats=1, num_hops=5, n_layers=2, num_heads=10).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([22]).to(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    loss_acc = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y\n",
    "\n",
    "        loss = criterion(output, label.reshape(-1, 1))\n",
    "        loss.backward()\n",
    "        loss_acc += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_acc / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, auc, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = np.asarray([])\n",
    "    labels = np.asarray([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            pred = torch.sigmoid(model(data).round().squeeze().cpu()).round().numpy()\n",
    "            label = data.y.cpu().numpy()\n",
    "\n",
    "            preds = np.concatenate([preds, pred])\n",
    "            labels = np.concatenate([labels, label])\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, preds, pos_label=1)\n",
    "    print(precision_recall_fscore_support(labels, preds))\n",
    "    return auc(fpr, tpr), auc(recall, precision)\n",
    "    return roc_auc_score(labels, preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billb\\anaconda3\\envs\\watai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.96560191, 0.        ]), array([1., 0.]), array([0.98249997, 0.        ]), array([341348,  12160], dtype=int64))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billb\\anaconda3\\envs\\watai\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.96558977, 0.        ]), array([1., 0.]), array([0.98249369, 0.        ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 001, Loss: 1.23038, Train Score: (0.5, 0.517199045000396), Val Score: (0.5, 0.517205114625104), Time: 20.97708s\n",
      "(array([0.98242573, 0.1081744 ]), array([0.82849467, 0.58396382]), array([0.89891801, 0.1825356 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9846107 , 0.10839006]), array([0.81114541, 0.64423923]), array([0.88949991, 0.18556048]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 002, Loss: 1.03815, Train Score: (0.7062292449232238, 0.353224530560125), Val Score: (0.727692319916775, 0.38243554602674823), Time: 14.39500s\n",
      "(array([0.98858541, 0.09939254]), array([0.7563425 , 0.75485197]), array([0.85700866, 0.17565615]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98984898, 0.09916162]), array([0.74573349, 0.78540018]), array([0.85062341, 0.17609071]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 003, Loss: 0.94841, Train Score: (0.7555972372961873, 0.43133856627963285), Val Score: (0.7655668350633144, 0.44597311424905683), Time: 14.40200s\n",
      "(array([0.98723998, 0.13556819]), array([0.84226654, 0.69440789]), array([0.90900928, 0.22684899]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98858084, 0.13747615]), array([0.83708138, 0.72867194]), array([0.90654515, 0.23131151]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 004, Loss: 0.88403, Train Score: (0.7683372189856562, 0.42024393247212743), Val Score: (0.7828766623323244, 0.43774227567388074), Time: 14.27700s\n",
      "(array([0.98773824, 0.1725487 ]), array([0.8816545 , 0.69276316]), array([0.93168636, 0.27628278]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98940011, 0.17021708]), array([0.87180894, 0.73790677]), array([0.92688982, 0.2766238 ]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 005, Loss: 0.80512, Train Score: (0.7872088285577367, 0.43794010837354486), Val Score: (0.804857853985495, 0.4585712714166792), Time: 14.20900s\n",
      "(array([0.98736526, 0.20842346]), array([0.90887599, 0.67351974]), array([0.94649621, 0.31833641]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98884048, 0.20279371]), array([0.89982918, 0.71503958]), array([0.94223732, 0.31597357]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 006, Loss: 0.75109, Train Score: (0.7911978613197954, 0.44658674893133654), Val Score: (0.8074343804463122, 0.4638194227167374), Time: 14.24100s\n",
      "(array([0.98900271, 0.20348093]), array([0.89971525, 0.71916118]), array([0.94224848, 0.31720986]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98940077, 0.19297636]), array([0.89088088, 0.73218997]), array([0.93755978, 0.30544854]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 007, Loss: 0.71531, Train Score: (0.8094382154105118, 0.46615121736644477), Val Score: (0.8115354281106115, 0.46719086703413254), Time: 14.31400s\n",
      "(array([0.98848475, 0.22334826]), array([0.91311506, 0.70139803]), array([0.94930627, 0.33880867]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98893748, 0.20938303]), array([0.90360596, 0.71635884]), array([0.944348  , 0.32405013]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 008, Loss: 0.69077, Train Score: (0.8072565438889961, 0.46750881188000476), Val Score: (0.8099824002023787, 0.46775101492111765), Time: 14.19900s\n",
      "(array([0.9954388, 0.1181825]), array([0.76018609, 0.90222039]), array([0.86205058, 0.20898934]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99287445, 0.11082993]), array([0.75772202, 0.84740545]), array([0.85950457, 0.19602258]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 009, Loss: 0.68638, Train Score: (0.831203240245485, 0.5118831650442133), Val Score: (0.8025637378975375, 0.4817430983502869), Time: 14.33000s\n",
      "(array([0.99336307, 0.15981707]), array([0.84230756, 0.84202303]), array([0.91162021, 0.26864497]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99127396, 0.15024179]), array([0.84027832, 0.79243624]), array([0.909552  , 0.25259322]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 010, Loss: 0.68577, Train Score: (0.8421652917064728, 0.5036370994915653), Val Score: (0.816357278813711, 0.4749101699908871), Time: 14.34300s\n",
      "(array([0.99268499, 0.16437278]), array([0.85077106, 0.82401316]), array([0.91626558, 0.27407377]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99095897, 0.15841055]), array([0.8519691 , 0.78188215]), array([0.91622287, 0.26344644]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 011, Loss: 0.65788, Train Score: (0.8373921092566129, 0.49721977213618906), Val Score: (0.8169256211177834, 0.4738990900909768), Time: 14.48300s\n",
      "(array([0.99368   , 0.17089468]), array([0.85350727, 0.84761513]), array([0.91827517, 0.28444089]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99126725, 0.1597828 ]), array([0.8520788 , 0.78935796]), array([0.91641806, 0.26576843]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 012, Loss: 0.64432, Train Score: (0.8505612013754447, 0.5118757804949139), Val Score: (0.8207183773673539, 0.47819450132605457), Time: 14.36800s\n",
      "(array([0.99485338, 0.1610457 ]), array([0.83697868, 0.87845395]), array([0.90911289, 0.27219101]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99155647, 0.14777525]), array([0.83551425, 0.8003518 ]), array([0.90687192, 0.24948595]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 013, Loss: 0.61444, Train Score: (0.8577163159390355, 0.5218402979393076), Val Score: (0.8179330280094, 0.477498497461959), Time: 14.37500s\n",
      "(array([0.99557885, 0.16547112]), array([0.83913191, 0.89539474]), array([0.91068522, 0.27932273]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99169731, 0.14917939]), array([0.83670527, 0.80343008]), array([0.90763202, 0.25163556]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 014, Loss: 0.58558, Train Score: (0.8672633245713742, 0.5322320413594139), Val Score: (0.8200676747034417, 0.47968674303342757), Time: 14.30500s\n",
      "(array([0.99412463, 0.20738239]), array([0.88381066, 0.85337171]), array([0.9357276 , 0.33367632]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99009884, 0.18175066]), array([0.87914309, 0.75329815]), array([0.93132787, 0.29284554]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 015, Loss: 0.58095, Train Score: (0.868591183549833, 0.5328989165041809), Val Score: (0.8162206237425504, 0.47176894163740685), Time: 14.71900s\n",
      "(array([0.99473725, 0.18158007]), array([0.85994352, 0.87228618]), array([0.92244214, 0.30058803]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99040052, 0.15755279]), array([0.85369294, 0.76781003]), array([0.91697948, 0.26145553]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 016, Loss: 0.56351, Train Score: (0.8661148511312425, 0.5291296845758136), Val Score: (0.8107514816698338, 0.46667626245613425), Time: 14.20500s\n",
      "(array([0.99506788, 0.19070804]), array([0.86706528, 0.87935855]), array([0.92666715, 0.31343984]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9914763 , 0.16825397]), array([0.86040024, 0.79243624]), array([0.92129948, 0.2775724 ]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 017, Loss: 0.56617, Train Score: (0.873211917491364, 0.537108215756508), Val Score: (0.8264182400899799, 0.48391626033764773), Time: 14.82900s\n",
      "(array([0.99565582, 0.19142792]), array([0.86548039, 0.89399671]), array([0.92601561, 0.31533452]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99149236, 0.16814324]), array([0.86021219, 0.79287599]), array([0.92119859, 0.27744864]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 018, Loss: 0.52791, Train Score: (0.8797385500204145, 0.5445354692981885), Val Score: (0.8265440892834541, 0.4840732088137948), Time: 14.90300s\n",
      "(array([0.99579768, 0.20396362]), array([0.87538524, 0.89629934]), array([0.93171713, 0.33230685]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99103275, 0.17724179]), array([0.87116641, 0.77880387]), array([0.92724179, 0.28876569]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 019, Loss: 0.51433, Train Score: (0.8858422897291728, 0.5519150333500535), Val Score: (0.8249851415736063, 0.48182853640797524), Time: 14.99300s\n",
      "(array([0.99561691, 0.20975109]), array([0.88038893, 0.89120066]), array([0.93446416, 0.33957948]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99050734, 0.18255386]), array([0.87810879, 0.76385224]), array([0.93092764, 0.29468148]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 020, Loss: 0.50273, Train Score: (0.8857947932477306, 0.5523471205094991), Val Score: (0.8209805163822963, 0.47726600176540546), Time: 14.84600s\n",
      "(array([0.99581632, 0.20550372]), array([0.87651312, 0.89662829]), array([0.93236377, 0.33437093]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99018285, 0.17642235]), array([0.87409694, 0.75681618]), array([0.92852565, 0.28614182]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 021, Loss: 0.50504, Train Score: (0.8865707040253102, 0.5528439007139865), Val Score: (0.815456562735487, 0.4708032706733548), Time: 14.28000s\n",
      "(array([0.99593596, 0.20707281]), array([0.87729824, 0.89950658]), array([0.93286025, 0.33664707]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99067591, 0.18072787]), array([0.87582078, 0.76868953]), array([0.92971453, 0.29265026]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 022, Loss: 0.51376, Train Score: (0.8884024100192858, 0.5550180856302886), Val Score: (0.8222551585557872, 0.4786884271525567), Time: 14.17900s\n",
      "(array([0.99574813, 0.19299706]), array([0.86651452, 0.89613487]), array([0.92664718, 0.31759494]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99164079, 0.1692998 ]), array([0.86074501, 0.79639402]), array([0.92156813, 0.2792383 ]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 023, Loss: 0.50410, Train Score: (0.8813246965937832, 0.5463523452672931), Val Score: (0.8285695159822721, 0.4863499757516744), Time: 14.14800s\n",
      "(array([0.99650694, 0.22178265]), array([0.8858965 , 0.91282895]), array([0.93795198, 0.35686155]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99118787, 0.18983414]), array([0.88135274, 0.78012313]), array([0.93304908, 0.30536191]), array([63811,  2274], dtype=int64))\n",
      "saving...\n",
      "Epoch: 024, Loss: 0.47176, Train Score: (0.8993627259077479, 0.5688050590411828), Val Score: (0.830737937935587, 0.48876164020783475), Time: 14.12400s\n",
      "(array([0.99628081, 0.22085411]), array([0.88599318, 0.90715461]), array([0.93790597, 0.35522566]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99112687, 0.1884644 ]), array([0.88049082, 0.77880387]), array([0.93253886, 0.30348728]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 025, Loss: 0.44824, Train Score: (0.8965738926218529, 0.5656012074295739), Val Score: (0.8296473471494474, 0.48743984145712255), Time: 14.10100s\n",
      "(array([0.99627276, 0.21913182]), array([0.88485358, 0.90707237]), array([0.93726349, 0.35298824]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99104383, 0.18647108]), array([0.87919011, 0.77704485]), array([0.93177213, 0.30076596]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 026, Loss: 0.43301, Train Score: (0.8959629744656326, 0.5647003591414615), Val Score: (0.8281174815849031, 0.48559393869162104), Time: 14.18600s\n",
      "(array([0.99584322, 0.21431099]), array([0.88291128, 0.89654605]), array([0.93598308, 0.34593051]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9908127 , 0.18292683]), array([0.87715284, 0.77176781]), array([0.93052485, 0.29575329]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 027, Loss: 0.43292, Train Score: (0.8897286668937334, 0.5572078298095312), Val Score: (0.8244603260064383, 0.48127408063697347), Time: 14.12200s\n",
      "(array([0.99658178, 0.24750379]), array([0.90108921, 0.91324013]), array([0.94643286, 0.38945781]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99043725, 0.20595623]), array([0.89595838, 0.75725594]), array([0.94083186, 0.32383639]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 028, Loss: 0.44008, Train Score: (0.9071646712947058, 0.5818641471166061), Val Score: (0.8266071568788915, 0.4857825204377421), Time: 14.18400s\n",
      "(array([0.99605748, 0.22886809]), array([0.89186695, 0.90090461]), array([0.94108719, 0.3650085 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99010178, 0.19184545]), array([0.88724515, 0.75109938]), array([0.93585579, 0.30562763]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 029, Loss: 0.40327, Train Score: (0.8963857781463029, 0.5665906938273999), Val Score: (0.8191722650830102, 0.4757547784727398), Time: 14.19700s\n",
      "(array([0.99522331, 0.24116213]), array([0.90152279, 0.87853618]), array([0.94605861, 0.37844061]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99058864, 0.20388464]), array([0.89401514, 0.76165347]), array([0.93982751, 0.32166404]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 030, Loss: 0.42637, Train Score: (0.8900294851704049, 0.5619382183468291), Val Score: (0.8278343062551408, 0.4868698353378349), Time: 14.22000s\n",
      "(array([0.9940203 , 0.22532751]), array([0.89605915, 0.84868421]), array([0.94250111, 0.35610766]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98991939, 0.19599907]), array([0.8910376 , 0.74538259]), array([0.93787939, 0.31038271]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 031, Loss: 0.40451, Train Score: (0.8723716821172774, 0.5396083477941015), Val Score: (0.8182100905754458, 0.47507155213898417), Time: 14.10000s\n",
      "(array([0.9960144 , 0.20906455]), array([0.87852866, 0.90131579]), array([0.93358986, 0.33940295]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99146931, 0.17867091]), array([0.87061792, 0.78979771]), array([0.92712193, 0.29141652]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 032, Loss: 0.45726, Train Score: (0.8899222232227274, 0.5568874442082713), Val Score: (0.8302078159106266, 0.48785086670846856), Time: 14.12500s\n",
      "(array([0.99589943, 0.25711046]), array([0.90787115, 0.89506579]), array([0.94985012, 0.39947148]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98991654, 0.21179423]), array([0.90155302, 0.74230431]), array([0.94367075, 0.32955877]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 033, Loss: 0.43092, Train Score: (0.9014684678176863, 0.5778928930317521), Val Score: (0.821928666679981, 0.4814829528634412), Time: 14.15900s\n",
      "(array([0.99625559, 0.27849899]), array([0.91663639, 0.90328947]), array([0.95478902, 0.42573643]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98966787, 0.22440468]), array([0.90965508, 0.73350923]), array([0.94797612, 0.34366952]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 034, Loss: 0.41417, Train Score: (0.9099629341070665, 0.592557558436831), Val Score: (0.82158215498614, 0.483541962487704), Time: 14.08700s\n",
      "(array([0.99704838, 0.25262212]), array([0.90251298, 0.925     ]), array([0.94742831, 0.39685984]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98915567, 0.19715277]), array([0.89483004, 0.72471416]), array([0.93963155, 0.30997837]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 035, Loss: 0.40296, Train Score: (0.9137564889789892, 0.5901009895766018), Val Score: (0.8097721025234661, 0.46566978920085395), Time: 14.11800s\n",
      "(array([0.99645267, 0.24087655]), array([0.89780517, 0.91027961]), array([0.94456028, 0.38094746]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98932434, 0.19987937]), array([0.8960524 , 0.72867194]), array([0.94038123, 0.31370693]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 036, Loss: 0.42455, Train Score: (0.9040423888485773, 0.5771211816266495), Val Score: (0.812362174234661, 0.46894388853433017), Time: 14.15800s\n",
      "(array([0.99181095, 0.19329125]), array([0.88170723, 0.79564145]), array([0.93352378, 0.31102324]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9876209 , 0.19247897]), array([0.89769789, 0.68425682]), array([0.94051489, 0.3004441 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 037, Loss: 0.43172, Train Score: (0.8386743393491624, 0.4979811183545912), Val Score: (0.7909773526308116, 0.44380029116440234), Time: 14.17400s\n",
      "(array([0.99562404, 0.27766905]), array([0.91782287, 0.88675987]), array([0.95514175, 0.4229125 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98849618, 0.22073255]), array([0.91164533, 0.70228672]), array([0.94851664, 0.33589231]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 038, Loss: 0.46801, Train Score: (0.9022913677036183, 0.5841620827753012), Val Score: (0.8069660235226039, 0.46663182588788915), Time: 14.10800s\n",
      "(array([0.99717371, 0.24713248]), array([0.89924066, 0.92845395]), array([0.9456785 , 0.39036028]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98939363, 0.20478953]), array([0.89904562, 0.72955145]), array([0.94205838, 0.31980723]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 039, Loss: 0.37904, Train Score: (0.9138473024982068, 0.5890237350954531), Val Score: (0.8142985351406109, 0.47182358995444446), Time: 14.15100s\n",
      "(array([0.99685677, 0.26201354]), array([0.90772467, 0.91965461]), array([0.95020508, 0.40783356]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98914105, 0.21298701]), array([0.90503205, 0.72119613]), array([0.94521916, 0.32885502]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 040, Loss: 0.34935, Train Score: (0.913689636671913, 0.5922159378540449), Val Score: (0.8131140889665828, 0.47188842411545723), Time: 14.11700s\n",
      "(array([0.99702356, 0.25307336]), array([0.90281472, 0.92434211]), array([0.94758334, 0.39735568]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98918554, 0.19886638]), array([0.89589569, 0.72515391]), array([0.94023223, 0.31213326]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 041, Loss: 0.33324, Train Score: (0.9135784140340187, 0.5900089737919657), Val Score: (0.8105248028868013, 0.46673890393685674), Time: 14.08000s\n",
      "(array([0.99685702, 0.24757754]), array([0.90036268, 0.9203125 ]), array([0.94615595, 0.39018863]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98835906, 0.19740741]), array([0.89812101, 0.70316623]), array([0.94108181, 0.30827068]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 042, Loss: 0.34384, Train Score: (0.9103375898643027, 0.585315569306858), Val Score: (0.8006436202656352, 0.4553938762507333), Time: 14.12100s\n",
      "(array([0.99688738, 0.25195752]), array([0.90260379, 0.92088816]), array([0.94740564, 0.39566108]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98927224, 0.19949343]), array([0.89598972, 0.72735268]), array([0.94032318, 0.31310932]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 043, Loss: 0.40297, Train Score: (0.9117459761314739, 0.587783486867399), Val Score: (0.8116712010693078, 0.4681139829023353), Time: 14.12500s\n",
      "(array([0.99856231, 0.25058803]), array([0.89732765, 0.96373355]), array([0.94524217, 0.39775311]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98984222, 0.19251337]), array([0.88878093, 0.74406332]), array([0.93659326, 0.30588448]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 044, Loss: 0.36605, Train Score: (0.9305306032607253, 0.6077845415969961), Val Score: (0.8164221278628357, 0.4726917665991952), Time: 14.14500s\n",
      "(array([0.99785757, 0.25830656]), array([0.90328052, 0.94555921]), array([0.94821656, 0.40576641]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98885312, 0.19612562]), array([0.89530018, 0.71679859]), array([0.93975408, 0.30798299]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 045, Loss: 0.33207, Train Score: (0.9244198668144193, 0.6028692159151318), Val Score: (0.8060493880710029, 0.4613346173934064), Time: 14.14000s\n",
      "(array([0.99606105, 0.3102791 ]), array([0.92897864, 0.896875  ]), array([0.96135102, 0.46105392]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98813659, 0.24144838]), array([0.92285029, 0.68909411]), array([0.95437823, 0.35759927]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 046, Loss: 0.33271, Train Score: (0.9129268188183319, 0.605350700293725), Val Score: (0.805972199784635, 0.47062041623465545), Time: 14.13400s\n",
      "(array([0.99669602, 0.27846897]), array([0.91556125, 0.91480263]), array([0.95440741, 0.42696759]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99000666, 0.22382719]), array([0.90821332, 0.74274406]), array([0.94734777, 0.34399185]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 047, Loss: 0.32744, Train Score: (0.9151819384970917, 0.5981011148564066), Val Score: (0.8254786903888209, 0.4877117461482331), Time: 14.15600s\n",
      "(array([0.9973291, 0.2987277]), array([0.92217034, 0.93067434]), array([0.95827828, 0.45228199]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98974559, 0.23553486]), array([0.91510868, 0.73394899]), array([0.95096491, 0.35662393]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 048, Loss: 0.36245, Train Score: (0.9264223392680597, 0.6158933536970245), Val Score: (0.8245288344439887, 0.4893193611637537), Time: 14.09000s\n",
      "(array([0.9959026 , 0.33794608]), array([0.93777025, 0.89169408]), array([0.9659626 , 0.49013448]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98777754, 0.26209952]), array([0.93214336, 0.67634125]), array([0.95915438, 0.37779415]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 049, Loss: 0.32802, Train Score: (0.9147321655034251, 0.6166828382452174), Val Score: (0.8042423048815814, 0.47478897178025037), Time: 14.12400s\n",
      "(array([0.99393578, 0.22958136]), array([0.89885981, 0.84605263]), array([0.94400994, 0.36115987]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98828426, 0.20643989]), array([0.90421714, 0.69920844]), array([0.94438352, 0.31876504]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 050, Loss: 0.33330, Train Score: (0.8724562230981441, 0.540464744574211), Val Score: (0.8017127922585038, 0.4579993177196379), Time: 14.11500s\n",
      "(array([0.99655147, 0.28070753]), array([0.91684732, 0.9109375 ]), array([0.95503933, 0.42916642]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9884396 , 0.22195904]), array([0.91249158, 0.7005277 ]), array([0.94894841, 0.33710718]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 051, Loss: 0.38564, Train Score: (0.9138924114832957, 0.5973543069558137), Val Score: (0.8065096405864467, 0.4663958253185312), Time: 14.10700s\n",
      "(array([0.99676338, 0.28808212]), array([0.91934331, 0.91620066]), array([0.95648927, 0.4383373 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9885929 , 0.22860409]), array([0.91539076, 0.70360598]), array([0.95058464, 0.34508789]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 052, Loss: 0.31572, Train Score: (0.917771983680954, 0.603582659843046), Val Score: (0.8094983719994239, 0.4712045265515367), Time: 14.13800s\n",
      "(array([0.99708431, 0.28332787]), array([0.91667155, 0.92475329]), array([0.95518852, 0.43375957]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98894372, 0.22800112]), array([0.91393333, 0.71328056]), array([0.94996009, 0.34554751]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 053, Loss: 0.30130, Train Score: (0.9207124193715258, 0.6053347534083543), Val Score: (0.8136069486314349, 0.475573884494782), Time: 14.14500s\n",
      "(array([0.99799589, 0.21960628]), array([0.87968583, 0.95041118]), array([0.93511359, 0.35677461]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98865613, 0.16760636]), array([0.87274921, 0.71899736]), array([0.927094  , 0.27184305]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 054, Loss: 0.38205, Train Score: (0.9150485090111774, 0.5858616115122908), Val Score: (0.7958732869978953, 0.4481365412020303), Time: 14.09200s\n",
      "(array([0.99707317, 0.25406321]), array([0.90319264, 0.92557566]), array([0.94781387, 0.39868934]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98893927, 0.20735275]), array([0.90235226, 0.71679859]), array([0.9436637 , 0.32165762]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 055, Loss: 0.34135, Train Score: (0.9143841470743239, 0.5910994592651654), Val Score: (0.809575425901471, 0.46694818611835764), Time: 14.12500s\n",
      "(array([0.99810668, 0.28332803]), array([0.9142781 , 0.95131579]), array([0.9543551 , 0.43661892]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98873985, 0.21362434]), array([0.90683424, 0.71020229]), array([0.94601753, 0.32845231]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 056, Loss: 0.32349, Train Score: (0.9327969434495929, 0.6181592299883558), Val Score: (0.8085182657994233, 0.466899315546973), Time: 14.13400s\n",
      "(array([0.99837355, 0.25986937]), array([0.90272977, 0.95871711]), array([0.94814575, 0.40890198]), array([341348,  12160], dtype=int64))\n",
      "(array([0.99047784, 0.20462633]), array([0.89492407, 0.7585752 ]), array([0.94027958, 0.32230942]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 057, Loss: 0.32265, Train Score: (0.9307234353905228, 0.6100032661406405), Val Score: (0.8267496352706162, 0.4857545075980372), Time: 14.12300s\n",
      "(array([0.99637068, 0.25036294]), array([0.90318678, 0.90764803]), array([0.94749313, 0.39246853]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98857733, 0.20238843]), array([0.90056573, 0.70800352]), array([0.94252138, 0.31479128]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 058, Loss: 0.35455, Train Score: (0.9054174017232299, 0.580593850644942), Val Score: (0.8042846256053514, 0.46021980943066154), Time: 14.10200s\n",
      "(array([0.99662059, 0.23262183]), array([0.89246751, 0.91504934]), array([0.94167286, 0.37094328]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98813247, 0.1864526 ]), array([0.89120998, 0.6996482 ]), array([0.93717196, 0.29443879]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 059, Loss: 0.33427, Train Score: (0.9037584266334464, 0.575296656299218), Val Score: (0.7954290882401495, 0.44821798360540427), Time: 14.14400s\n",
      "(array([0.99625612, 0.27155002]), array([0.91364824, 0.90361842]), array([0.95316569, 0.41760413]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98761557, 0.20742329]), array([0.90730438, 0.68073879]), array([0.94575809, 0.31796241]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 060, Loss: 0.33097, Train Score: (0.9086333313648736, 0.589241891525171), Val Score: (0.7940215847682444, 0.4495739630281969), Time: 14.15600s\n",
      "(array([0.99573066, 0.29529743]), array([0.92444661, 0.88873355]), array([0.95876547, 0.44330045]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98676198, 0.22411454]), array([0.91932425, 0.65391381]), array([0.95185014, 0.33381973]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 061, Loss: 0.32168, Train Score: (0.9065900792207428, 0.5939291673266084), Val Score: (0.7866190313531299, 0.4449686287748112), Time: 14.15500s\n",
      "(array([0.99633858, 0.32361602]), array([0.93270797, 0.90378289]), array([0.96347383, 0.47658283]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98780345, 0.24775353]), array([0.92653304, 0.67897977]), array([0.95618773, 0.36303786]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 062, Loss: 0.32084, Train Score: (0.918245432158137, 0.6153542991145005), Val Score: (0.8027564071101738, 0.46888984057874633), Time: 14.16300s\n",
      "(array([0.99650987, 0.28640601]), array([0.91926421, 0.90962171]), array([0.95632974, 0.43564395]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98640868, 0.21426488]), array([0.91557882, 0.64599824]), array([0.9496749 , 0.32179628]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 063, Loss: 0.32215, Train Score: (0.9144429609148682, 0.5995682791559395), Val Score: (0.7807885298420094, 0.4362222000736548), Time: 14.25400s\n",
      "(array([0.99603286, 0.33120399]), array([0.93559066, 0.89539474]), array([0.96486611, 0.48354577]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98596684, 0.23798437]), array([0.9281942, 0.6292876]), array([0.95620868, 0.3453602 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 064, Loss: 0.30913, Train Score: (0.915492697528005, 0.6150984745473456), Val Score: (0.7787408987185069, 0.4400141324275966), Time: 14.10200s\n",
      "(array([0.998015  , 0.36465785]), array([0.94119491, 0.94745066]), array([0.96877252, 0.52662614]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98867386, 0.2751643 ]), array([0.93432167, 0.6996482 ]), array([0.96072965, 0.3949851 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 065, Loss: 0.30148, Train Score: (0.9443227837442326, 0.6569580506602464), Val Score: (0.8169849328437444, 0.49257383720781217), Time: 14.09400s\n",
      "(array([0.99792365, 0.39743945]), array([0.94898461, 0.94457237]), array([0.97283905, 0.55947394]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98768129, 0.29296424]), array([0.94236103, 0.6701847 ]), array([0.96448907, 0.40770465]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 066, Loss: 0.25292, Train Score: (0.9467784911817112, 0.671959209723709), Val Score: (0.8062728657506011, 0.4872489806462574), Time: 14.13700s\n",
      "(array([0.99808712, 0.3997298 ]), array([0.94923656, 0.94893092]), array([0.9730491 , 0.56250762]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98768776, 0.29477756]), array([0.94286252, 0.6701847 ]), array([0.96475474, 0.40945728]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 067, Loss: 0.24498, Train Score: (0.9490837386471778, 0.6752086975472369), Val Score: (0.8065236062185454, 0.488155639816923), Time: 14.13800s\n",
      "(array([0.99819252, 0.40259514]), array([0.94969064, 0.95172697]), array([0.97333774, 0.56583386]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98771164, 0.29709721]), array([0.94345802, 0.67062445]), array([0.96507779, 0.41177265]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 068, Loss: 0.23990, Train Score: (0.9507088059885481, 0.6779913086300974), Val Score: (0.8070412373931829, 0.48952777629348027), Time: 14.10300s\n",
      "(array([0.99823054, 0.40577933]), array([0.95029999, 0.95271382]), array([0.97367576, 0.56914763]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98760656, 0.29852507]), array([0.94410055, 0.66754617]), array([0.96536363, 0.41255605]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 069, Loss: 0.23482, Train Score: (0.9515069014497013, 0.6800598523553086), Val Score: (0.8058233605350629, 0.4887555301258295), Time: 14.14600s\n",
      "(array([0.99828052, 0.40834213]), array([0.950757  , 0.95402961]), array([0.97393937, 0.57190042]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9875295 , 0.29895278]), array([0.9443983 , 0.66534741]), array([0.96548244, 0.4125426 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 070, Loss: 0.23108, Train Score: (0.9523933019929346, 0.681976516045215), Val Score: (0.8048728533431381, 0.4879078270408434), Time: 14.14600s\n",
      "(array([0.99833152, 0.4139762 ]), array([0.95182336, 0.95534539]), array([0.97452287, 0.57764408]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98738485, 0.30253623]), array([0.94569902, 0.66094987]), array([0.96609247, 0.41507871]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 071, Loss: 0.22701, Train Score: (0.9535843769446893, 0.6854288117172965), Val Score: (0.8033244427423348, 0.48757644636241393), Time: 14.14100s\n",
      "(array([0.99845423, 0.41478081]), array([0.9518175 , 0.95863487]), array([0.97457825, 0.57902841]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98743373, 0.30307909]), array([0.94573036, 0.66226913]), array([0.96613222, 0.41584979]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 072, Loss: 0.22481, Train Score: (0.9552261842251741, 0.6874192820294932), Val Score: (0.8039997446284417, 0.4884848081669592), Time: 14.14100s\n",
      "(array([0.99847668, 0.41800459]), array([0.95242392, 0.95921053]), array([0.97490674, 0.58226837]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98744113, 0.3052909 ]), array([0.94629453, 0.66226913]), array([0.96643006, 0.41792702]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 073, Loss: 0.22053, Train Score: (0.9558172228002539, 0.6893090967293136), Val Score: (0.8042818276548791, 0.48959071200366794), Time: 14.14903s\n",
      "(array([0.99856284, 0.41959447]), array([0.9526202 , 0.96151316]), array([0.97505064, 0.58423485]), array([341348,  12160], dtype=int64))\n",
      "(array([0.987454  , 0.30444444]), array([0.94604379, 0.66270888]), array([0.96630544, 0.41722038]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 074, Loss: 0.21781, Train Score: (0.957066678904011, 0.6912157525534947), Val Score: (0.8043763342898602, 0.4893797960645506), Time: 14.09100s\n",
      "(array([0.99860351, 0.42270052]), array([0.95316803, 0.96258224]), array([0.97535692, 0.58743821]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98737217, 0.30815028]), array([0.94718779, 0.66007036]), array([0.96686263, 0.42015395]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 075, Loss: 0.21442, Train Score: (0.9578751323892025, 0.693284926420057), Val Score: (0.803629074768638, 0.4899588472846544), Time: 14.13200s\n",
      "(array([0.99859536, 0.42638003]), array([0.95387991, 0.96233553]), array([0.9757256 , 0.59093549]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98733309, 0.31059507]), array([0.947893 , 0.6587511]), array([0.96721115, 0.4221502 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 076, Loss: 0.21237, Train Score: (0.958107718862923, 0.6950055725321349), Val Score: (0.8033220479448248, 0.49054430879897865), Time: 14.16000s\n",
      "(array([0.99870558, 0.42694504]), array([0.95384476, 0.96529605]), array([0.97575982, 0.59203591]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9872835 , 0.30978036]), array([0.94779897, 0.65743184]), array([0.9671384 , 0.42112676]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 077, Loss: 0.20954, Train Score: (0.9595704046510954, 0.6967174213461591), Val Score: (0.802615403500225, 0.48950002177790686), Time: 14.11300s\n",
      "(array([0.99874928, 0.43053927]), array([0.95446289, 0.96644737]), array([0.97610402, 0.59570154]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98725938, 0.31201672]), array([0.94841015, 0.65655233]), array([0.96744491, 0.42300609]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 078, Loss: 0.20667, Train Score: (0.9604551312967844, 0.6990703940077221), Val Score: (0.8024812397076254, 0.49019358132216134), Time: 14.09600s\n",
      "(array([0.99878013, 0.43172809]), array([0.95464453, 0.96726974]), array([0.97621373, 0.59699523]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98718283, 0.31253938]), array([0.9487079 , 0.65435356]), array([0.96756303, 0.42302772]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 079, Loss: 0.20429, Train Score: (0.960957131917543, 0.7000618411490903), Val Score: (0.8015307325157006, 0.48939335882943247), Time: 14.17600s\n",
      "(array([0.99884176, 0.43392752]), array([0.95497264, 0.96891447]), array([0.9764147 , 0.59940985]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98721961, 0.31427969]), array([0.94905267, 0.65523307]), array([0.96775998, 0.42480399]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 080, Loss: 0.20243, Train Score: (0.961943555789338, 0.7019556377837934), Val Score: (0.8021428703253192, 0.4906881332138544), Time: 14.14600s\n",
      "(array([0.99869995, 0.44119859]), array([0.95645793, 0.96504934]), array([0.97712261, 0.6055524 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98705123, 0.32046834]), array([0.95088621, 0.64995602]), array([0.96863127, 0.42927679]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 081, Loss: 0.19994, Train Score: (0.9607536338706356, 0.7037250821704949), Val Score: (0.8004211177338001, 0.4912347307591701), Time: 14.15100s\n",
      "(array([0.99887324, 0.43825027]), array([0.95571968, 0.96973684]), array([0.97682009, 0.60368086]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98716842, 0.31792897]), array([0.95003996, 0.65347405]), array([0.96824839, 0.42774899]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 082, Loss: 0.19907, Train Score: (0.9627282591064652, 0.7045140531904235), Val Score: (0.801757008145771, 0.4916635302588108), Time: 14.19200s\n",
      "(array([0.99893442, 0.4386838 ]), array([0.95572261, 0.97138158]), array([0.97685087, 0.60441079]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98711831, 0.31688034]), array([0.94989892, 0.65215479]), array([0.96815104, 0.42651711]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 083, Loss: 0.19649, Train Score: (0.963552092308328, 0.7055248990074919), Val Score: (0.8010268567823016, 0.4905022842508382), Time: 14.16700s\n",
      "(array([0.99892356, 0.44550085]), array([0.95694423, 0.97105263]), array([0.97748339, 0.61078495]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9870567 , 0.32228522]), array([0.95129366, 0.64995602]), array([0.96884526, 0.43090379]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 084, Loss: 0.19403, Train Score: (0.9639984322219707, 0.7087746073298078), Val Score: (0.8006248443640049, 0.492143166970438), Time: 14.06100s\n",
      "(array([0.99882704, 0.45066973]), array([0.95794907, 0.96842105]), array([0.97796108, 0.61509533]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98694021, 0.3250774 ]), array([0.95217126, 0.64643799]), array([0.96924402, 0.43260742]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 085, Loss: 0.19127, Train Score: (0.963185062566185, 0.7100885181934784), Val Score: (0.7993046252312807, 0.4918407718797532), Time: 14.16500s\n",
      "(array([0.99886103, 0.4530151 ]), array([0.95830648, 0.96932566]), array([0.97816359, 0.61745986]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98687115, 0.3281075 ]), array([0.95298616, 0.64423923]), array([0.96963271, 0.43478261]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 086, Loss: 0.19016, Train Score: (0.9638160684566083, 0.711697950511006), Val Score: (0.7986126941469233, 0.49229426931169745), Time: 14.16300s\n",
      "(array([0.99893127, 0.45391652]), array([0.95837679, 0.97121711]), array([0.97823389, 0.61868092]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98688631, 0.32796421]), array([0.95292348, 0.64467898]), array([0.96960758, 0.43475682]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 087, Loss: 0.18672, Train Score: (0.9647969468802636, 0.7130618505997844), Val Score: (0.7988012284573835, 0.49243493167568464), Time: 14.12500s\n",
      "(array([0.99886453, 0.45531093]), array([0.95868732, 0.96940789]), array([0.97836362, 0.61960578]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9867337 , 0.32903955]), array([0.95347197, 0.64028144]), array([0.96981773, 0.43469175]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 088, Loss: 0.18671, Train Score: (0.9640476083829869, 0.7128855677941671), Val Score: (0.7968767071546641, 0.4908494942238479), Time: 14.11300s\n",
      "(array([0.99895906, 0.45601512]), array([0.95869611, 0.97195724]), array([0.97841355, 0.6207784 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98690084, 0.32760161]), array([0.95281378, 0.64511873]), array([0.9695578 , 0.43453791]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 089, Loss: 0.18561, Train Score: (0.965326673778049, 0.7144684894784475), Val Score: (0.7989662558489742, 0.4924659435532192), Time: 14.21100s\n",
      "(array([0.99895914, 0.45642016]), array([0.95876349, 0.97195724]), array([0.97844867, 0.62115359]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98674411, 0.32726864]), array([0.95306452, 0.6407212 ]), array([0.96961194, 0.43324413]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 090, Loss: 0.18297, Train Score: (0.9653603637366835, 0.7146710063324028), Val Score: (0.7968928573934126, 0.4901763527212239), Time: 14.13100s\n",
      "(array([0.99909005, 0.45591514]), array([0.95852913, 0.97549342]), array([0.97838939, 0.621405  ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98684659, 0.3250444 ]), array([0.95235931, 0.64379947]), array([0.96929629, 0.43198584]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 091, Loss: 0.18220, Train Score: (0.9670112733771308, 0.7161257681180883), Val Score: (0.7980793916930394, 0.4905504095431139), Time: 14.13900s\n",
      "(array([0.99889354, 0.46379148]), array([0.96004371, 0.97014803]), array([0.97908339, 0.62756676]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98665306, 0.33348666]), array([0.95458463, 0.63764292]), array([0.97035397, 0.43793416]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 092, Loss: 0.18057, Train Score: (0.9650958676875828, 0.7174831769202759), Val Score: (0.7961137763541952, 0.4917991853464225), Time: 14.15800s\n",
      "(array([0.99896971, 0.46459168]), array([0.96008765, 0.97220395]), array([0.97914283, 0.62872946]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98659926, 0.33096981]), array([0.95416151, 0.63632366]), array([0.9701093 , 0.43544989]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 093, Loss: 0.17963, Train Score: (0.9661457999260517, 0.7188758814198419), Val Score: (0.7952425834775071, 0.4899038264473018), Time: 14.21700s\n",
      "(array([0.9991124 , 0.46258477]), array([0.95960427, 0.97606908]), array([0.97895989, 0.62769052]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98672179, 0.33030647]), array([0.95376973, 0.63984169]), array([0.96996597, 0.43569397]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 094, Loss: 0.17716, Train Score: (0.9678366768818425, 0.719738512903269), Val Score: (0.7968057074385526, 0.49127064431733497), Time: 14.17800s\n",
      "(array([0.99917998, 0.46693631]), array([0.9602312 , 0.97787829]), array([0.97931848, 0.63206294]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98685384, 0.33295403]), array([0.95406748, 0.64335972]), array([0.97018374, 0.43881224]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 095, Loss: 0.17517, Train Score: (0.969054745238383, 0.7227877706482567), Val Score: (0.7987135995430217, 0.4942929103110998), Time: 14.15600s\n",
      "(array([0.99909819, 0.46934093]), array([0.96070286, 0.97565789]), array([0.97952442, 0.63379454]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98657055, 0.33180253]), array([0.95439658, 0.63544415]), array([0.9702169 , 0.43596319]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 096, Loss: 0.17499, Train Score: (0.9681803775804041, 0.7229180727677239), Val Score: (0.7949203643339492, 0.489895563718392), Time: 14.16900s\n",
      "(array([0.99902904, 0.47428503]), array([0.9615495 , 0.97376645]), array([0.97993103, 0.63788181]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98661574, 0.33682495]), array([0.95535253, 0.63632366]), array([0.97073248, 0.44048706]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 097, Loss: 0.17389, Train Score: (0.9676579755503413, 0.7244769295552349), Val Score: (0.795838092088875, 0.49283139923570807), Time: 14.12600s\n",
      "(array([0.99905945, 0.47449552]), array([0.9615495 , 0.97458882]), array([0.97994566, 0.6382486 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98649457, 0.33795209]), array([0.95582266, 0.63280563]), array([0.97091644, 0.44060012]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 098, Loss: 0.17167, Train Score: (0.9680691597608675, 0.7249792138430207), Val Score: (0.7943141463259458, 0.4916964807608807), Time: 14.09200s\n",
      "(array([0.99906603, 0.47784721]), array([0.96205632, 0.97475329]), array([0.98021195, 0.64130935]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98672123, 0.34132018]), array([0.95605773, 0.63896218]), array([0.97114749, 0.44495483]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 099, Loss: 0.17032, Train Score: (0.9684048036831373, 0.7267344681593704), Val Score: (0.7975099570856421, 0.49635287691083113), Time: 14.17800s\n",
      "(array([0.99925672, 0.47220131]), array([0.96098117, 0.97993421]), array([0.97974526, 0.63730445]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98662825, 0.33572919]), array([0.95510178, 0.63676341]), array([0.97060908, 0.43965386]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 100, Loss: 0.16962, Train Score: (0.9704576896521099, 0.7264128715330588), Val Score: (0.7959325987238562, 0.4924958287778892), Time: 14.09800s\n",
      "(array([0.99919318, 0.47467976]), array([0.96143525, 0.97820724]), array([0.97995064, 0.63918966]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98662586, 0.33487512]), array([0.9549294 , 0.63676341]), array([0.97051891, 0.43892089]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 101, Loss: 0.17014, Train Score: (0.9698212438355855, 0.7268183110234722), Val Score: (0.7958464066880003, 0.49206879118549757), Time: 14.14300s\n",
      "(array([0.99913316, 0.48026369]), array([0.9623522, 0.9765625]), array([0.98039783, 0.64387573]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98636555, 0.34185991]), array([0.95685697, 0.62884785]), array([0.97138721, 0.44293015]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 102, Loss: 0.16833, Train Score: (0.9694573518081254, 0.7288161976386317), Val Score: (0.7928524067205006, 0.4917395925479695), Time: 14.13700s\n",
      "(array([0.99910927, 0.48306603]), array([0.9627975 , 0.97590461]), array([0.98061734, 0.64624517]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98656318, 0.34033019]), array([0.95616743, 0.63456464]), array([0.97112752, 0.44304575]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 103, Loss: 0.16686, Train Score: (0.9693510511228548, 0.7298997335175073), Val Score: (0.7953660378734712, 0.49373477343085465), Time: 14.18100s\n",
      "(array([0.99921491, 0.47831853]), array([0.96197136, 0.97878289]), array([0.9802395 , 0.64260454]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98640237, 0.33829084]), array([0.9560734 , 0.63016711]), array([0.97100111, 0.44024578]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 104, Loss: 0.16393, Train Score: (0.9703771276712206, 0.728915626678514), Val Score: (0.7931202553461977, 0.4905919907441163), Time: 14.05100s\n",
      "(array([0.99921243, 0.48281878]), array([0.96265395, 0.97870066]), array([0.98059256, 0.64663533]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9865199 , 0.34155598]), array([0.95649653, 0.63324538]), array([0.97127626, 0.44375963]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 105, Loss: 0.16474, Train Score: (0.9706773031789444, 0.7311260450954947), Val Score: (0.7948709556986995, 0.4937107351395751), Time: 14.12300s\n",
      "(array([0.99944823, 0.47024417]), array([0.96046557, 0.98511513]), array([0.97956921, 0.6366052 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98673413, 0.32918833]), array([0.95350331, 0.64028144]), array([0.96983415, 0.43482156]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 106, Loss: 0.16675, Train Score: (0.9727903487558305, 0.7279356565746782), Val Score: (0.7968923784339106, 0.4909238870676242), Time: 14.11800s\n",
      "(array([0.99931858, 0.4815816 ]), array([0.96235806, 0.98157895]), array([0.98049013, 0.64614968]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98661812, 0.33768961]), array([0.95552491, 0.63632366]), array([0.97082262, 0.4412258 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 107, Loss: 0.16295, Train Score: (0.9719685050539564, 0.7318970990850093), Val Score: (0.7959242841247308, 0.4932637299810868), Time: 14.08600s\n",
      "(array([0.99955179, 0.47047074]), array([0.9603894 , 0.98791118]), array([0.97957934, 0.63739587]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98656869, 0.32582244]), array([0.95311153, 0.63588391]), array([0.96955156, 0.43087008]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 108, Loss: 0.16136, Train Score: (0.9741502907705549, 0.7293988806366114), Val Score: (0.794497718753795, 0.4871178329285324), Time: 14.07500s\n",
      "(array([0.99937059, 0.48530248]), array([0.96286195, 0.98297697]), array([0.98077663, 0.64979614]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98642336, 0.34029426]), array([0.95643384, 0.63060686]), array([0.97119715, 0.44204686]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 109, Loss: 0.16191, Train Score: (0.9729194605112054, 0.7344325049649968), Val Score: (0.7935203519264862, 0.4918060100107484), Time: 14.13100s\n",
      "(array([0.99918635, 0.49289178]), array([0.96415681, 0.97796053]), array([0.98135909, 0.65544134]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98609229, 0.34397077]), array([0.95779724, 0.62093228]), array([0.97173884, 0.44270262]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 110, Loss: 0.16202, Train Score: (0.9710586699451031, 0.7358052115536992), Val Score: (0.7893647614567354, 0.4889734262496105), Time: 14.05900s\n",
      "(array([0.99904821, 0.50188535]), array([0.96555714, 0.97417763]), array([0.98201721, 0.66247239]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98602502, 0.3537997 ]), array([0.95975615, 0.61829376]), array([0.97271327, 0.45006402]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 111, Loss: 0.15825, Train Score: (0.9698673878039574, 0.7384756126443397), Val Score: (0.7890249551959229, 0.49261402645687535), Time: 14.10500s\n",
      "(array([0.99923803, 0.49416988]), array([0.96428864, 0.97935855]), array([0.9814523 , 0.65688519]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98631795, 0.34729664]), array([0.95800097, 0.62708883]), array([0.97195326, 0.44702194]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 112, Loss: 0.15791, Train Score: (0.9718235982394567, 0.737119230781823), Val Score: (0.7925449009371852, 0.4936087140803636), Time: 14.11800s\n",
      "(array([0.99948305, 0.48623221]), array([0.96288538, 0.98601974]), array([0.98084295, 0.65129417]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98653019, 0.33961819]), array([0.95608908, 0.63368514]), array([0.97107112, 0.44222802]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 113, Loss: 0.15647, Train Score: (0.9744525603366344, 0.736366419250061), Val Score: (0.794887105937448, 0.49295415471705023), Time: 14.13700s\n",
      "(array([0.99951572, 0.47655164]), array([0.96138252, 0.98692434]), array([0.98007834, 0.64274429]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98666364, 0.33173297]), array([0.95419285, 0.63808267]), array([0.97015663, 0.43652226]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 114, Loss: 0.16024, Train Score: (0.974153430412581, 0.7319628808715235), Val Score: (0.796137762232567, 0.4911346497028374), Time: 14.09500s\n",
      "(array([0.99921952, 0.49141277]), array([0.96391073, 0.97886513]), array([0.9812476 , 0.65433456]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98640896, 0.34070376]), array([0.95654354, 0.63016711]), array([0.97124672, 0.44228395]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 115, Loss: 0.15798, Train Score: (0.9713879309886253, 0.7355024479698884), Val Score: (0.7933553245348955, 0.49179844880551243), Time: 14.13806s\n",
      "(array([0.99942575, 0.49091655]), array([0.96363242, 0.98445724]), array([0.98120277, 0.6551375 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98647098, 0.34068279]), array([0.95641817, 0.63192612]), array([0.97121215, 0.44269871]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 116, Loss: 0.15693, Train Score: (0.9740448294432353, 0.7379542126328444), Val Score: (0.794172146893723, 0.4926372079839212), Time: 14.08600s\n",
      "(array([0.99948622, 0.48799447]), array([0.96314319, 0.98610197]), array([0.98097821, 0.65289121]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98654157, 0.33810082]), array([0.95575998, 0.63412489]), array([0.97090686, 0.44104603]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 117, Loss: 0.15501, Train Score: (0.9746225794689846, 0.7372872522446244), Val Score: (0.7949424343743129, 0.49240777855227597), Time: 14.06500s\n",
      "(array([0.99955833, 0.47665331]), array([0.96135322, 0.98807566]), array([0.9800836 , 0.64308079]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98681458, 0.33009489]), array([0.95353466, 0.64248021]), array([0.96988922, 0.4361194 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 118, Loss: 0.15480, Train Score: (0.9747144404992157, 0.7325695715380013), Val Score: (0.798007434057924, 0.4924387213946322), Time: 14.09300s\n",
      "(array([0.99940537, 0.50075339]), array([0.96505619, 0.98388158]), array([0.98193048, 0.66370798]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98638962, 0.34506872]), array([0.95743681, 0.6292876 ]), array([0.97169759, 0.44572496]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 119, Loss: 0.15300, Train Score: (0.974468883969624, 0.74259470605078), Val Score: (0.7933622022555147, 0.49355631101493597), Time: 14.11500s\n",
      "(array([0.99958997, 0.49552891]), array([0.96413631, 0.98889803]), array([0.98154309, 0.66022456]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98639829, 0.34250179]), array([0.95691965, 0.62972735]), array([0.97143539, 0.44368706]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 120, Loss: 0.15129, Train Score: (0.9765171664794317, 0.7424044102878581), Val Score: (0.7933235030169005, 0.49248515659550096), Time: 14.10700s\n",
      "(array([0.99941223, 0.51029895]), array([0.96635984, 0.98404605]), array([0.98260816, 0.67207728]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98639313, 0.35868474]), array([0.95995988, 0.62840809]), array([0.97299701, 0.45669543]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 121, Loss: 0.14916, Train Score: (0.9752029482722678, 0.7474468922996014), Val Score: (0.7941839864969532, 0.4999396965923413), Time: 14.06200s\n",
      "(array([0.99951168, 0.50396909]), array([0.96540188, 0.98675987]), array([0.98216071, 0.66718563]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98636437, 0.3472661 ]), array([0.95790694, 0.62840809]), array([0.9719274 , 0.44733135]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 122, Loss: 0.15013, Train Score: (0.9760808728420695, 0.7455921954893243), Val Score: (0.7931575177063058, 0.49423037693216954), Time: 14.10300s\n",
      "(array([0.99949561, 0.49157752]), array([0.96365879, 0.98634868]), array([0.9812501 , 0.65614486]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98690176, 0.33904189]), array([0.95524283, 0.64423923]), array([0.97081425, 0.44427597]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 123, Loss: 0.14971, Train Score: (0.9750037361547377, 0.7391978935343423), Val Score: (0.7997410262526731, 0.497761462137795), Time: 14.08200s\n",
      "(array([0.99952671, 0.50221739]), array([0.96514408, 0.98717105]), array([0.98203454, 0.66574233]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98637844, 0.35275241]), array([0.95890991, 0.62840809]), array([0.97245024, 0.45185771]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 124, Loss: 0.14982, Train Score: (0.9761575642360351, 0.7449148657920387), Val Score: (0.7936589986421947, 0.4969735305209959), Time: 14.08400s\n",
      "(array([0.9996051 , 0.49481737]), array([0.96401912, 0.98930921]), array([0.98148966, 0.65968414]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9866311 , 0.34248521]), array([0.95646519, 0.63632366]), array([0.97131399, 0.44529928]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 125, Loss: 0.14828, Train Score: (0.976664167352287, 0.7422471637005201), Val Score: (0.7963944225021267, 0.49566152606347136), Time: 14.09300s\n",
      "(array([0.99946893, 0.49970814]), array([0.96484819, 0.98560855]), array([0.98185347, 0.66318061]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98646881, 0.3456909 ]), array([0.95740546, 0.63148637]), array([0.97171987, 0.44679527]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 126, Loss: 0.14910, Train Score: (0.9752283713742048, 0.7429058648462862), Val Score: (0.7944459153210351, 0.49492895327134306), Time: 14.10500s\n",
      "(array([0.99964798, 0.50223093]), array([0.96502982, 0.99046053]), array([0.98203391, 0.66650065]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98658834, 0.34990301]), array([0.9579853 , 0.63456464]), array([0.97207646, 0.45107846]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 127, Loss: 0.14799, Train Score: (0.9777451746265426, 0.7465097994059783), Val Score: (0.7962749720697695, 0.49852118248599436), Time: 14.12100s\n",
      "(array([0.99959705, 0.51300973]), array([0.96655319, 0.9890625 ]), array([0.98279745, 0.67559825]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98631703, 0.3592331 ]), array([0.96019495, 0.62620932]), array([0.97308071, 0.45655659]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 128, Loss: 0.14425, Train Score: (0.9778078474899516, 0.7512242272061165), Val Score: (0.7932021367465352, 0.4991523217774643), Time: 14.11500s\n",
      "(array([0.99963513, 0.48887445]), array([0.96312268, 0.99013158]), array([0.98103929, 0.65456127]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98679318, 0.34501539]), array([0.95665324, 0.6407212 ]), array([0.9714895, 0.4485147]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 129, Loss: 0.14644, Train Score: (0.9766271286348922, 0.7396727428131664), Val Score: (0.7986872188671396, 0.4990497270187802), Time: 14.11000s\n",
      "(array([0.99969025, 0.49814096]), array([0.96441169, 0.99161184]), array([0.98173414, 0.6631469 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98658227, 0.34754335]), array([0.9575465 , 0.63456464]), array([0.97184756, 0.44911298]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 130, Loss: 0.14416, Train Score: (0.9780117637703273, 0.7450206677515203), Val Score: (0.7960555741603182, 0.49734135539181007), Time: 14.12100s\n",
      "(array([0.99966808, 0.47975636]), array([0.96171649, 0.99103618]), array([0.98032511, 0.64653022]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98698517, 0.32982299]), array([0.9531272, 0.6473175]), array([0.96976075, 0.43698976]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 131, Loss: 0.14469, Train Score: (0.9763763364775752, 0.7355504410402496), Val Score: (0.8002223529862064, 0.4946381884107415), Time: 14.09600s\n",
      "(array([0.99968375, 0.48904754]), array([0.96309924, 0.99144737]), array([0.98105055, 0.6550038 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98671714, 0.33980355]), array([0.95575998, 0.63896218]), array([0.97099188, 0.44366412]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 132, Loss: 0.15346, Train Score: (0.9772733051252527, 0.7403945521967243), Val Score: (0.7973610799328, 0.4955945650081114), Time: 14.14900s\n",
      "(array([0.99947318, 0.51605959]), array([0.96707173, 0.98569079]), array([0.98300552, 0.67744306]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98608497, 0.35925548]), array([0.96061808, 0.61961302]), array([0.97318494, 0.45480955]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 133, Loss: 0.14718, Train Score: (0.976381258430199, 0.7511212936887638), Val Score: (0.7901155459820625, 0.4959788509532076), Time: 14.09400s\n",
      "(array([0.99939201, 0.52199913]), array([0.96791837, 0.98347039]), array([0.98340343, 0.68200741]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98607672, 0.36223308]), array([0.9611509 , 0.61917326]), array([0.97345428, 0.45706866]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 134, Loss: 0.14496, Train Score: (0.9756943827159256, 0.7530190543025653), Val Score: (0.7901620808602999, 0.4972553414697818), Time: 14.10000s\n",
      "(array([0.99962091, 0.50624658]), array([0.96561281, 0.98972039]), array([0.9823226 , 0.66985779]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98632677, 0.35071323]), array([0.95862782, 0.62708883]), array([0.97228006, 0.44984227]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 135, Loss: 0.14303, Train Score: (0.9776666002182985, 0.7481602878905196), Val Score: (0.7928583265221157, 0.49531701038663406), Time: 14.08700s\n",
      "(array([0.9994789 , 0.51145527]), array([0.96645359, 0.98585526]), array([0.98268885, 0.67350206]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98632696, 0.35696393]), array([0.95977183, 0.62664908]), array([0.97286822, 0.45483562]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 136, Loss: 0.14309, Train Score: (0.9761544265213523, 0.7488985409758739), Val Score: (0.7932104513456605, 0.49823004762034173), Time: 14.17100s\n",
      "(array([0.99947587, 0.51145624]), array([0.96645652, 0.98577303]), array([0.9826889 , 0.67348372]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98646449, 0.3561848 ]), array([0.95938004, 0.63060686]), array([0.97273377, 0.4552381 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 137, Loss: 0.14148, Train Score: (0.9761147728811098, 0.7488593257184492), Val Score: (0.7949934521756595, 0.49975128079573383), Time: 14.15300s\n",
      "(array([0.99950394, 0.48145919]), array([0.96214713, 0.98659539]), array([0.98046983, 0.64712228]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98671807, 0.33448355]), array([0.95466299, 0.63940193]), array([0.97042589, 0.43920858]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 138, Loss: 0.14470, Train Score: (0.9743712645198326, 0.7342578368428087), Val Score: (0.7970324620281252, 0.49314687443900473), Time: 14.10700s\n",
      "(array([0.99954491, 0.50248944]), array([0.96516458, 0.98766447]), array([0.98205394, 0.66609356]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98674245, 0.34944685]), array([0.95760919, 0.63896218]), array([0.97195756, 0.45180348]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 139, Loss: 0.14556, Train Score: (0.9764145282280224, 0.7452891139085486), Val Score: (0.7982856854083451, 0.5004162123695155), Time: 14.14600s\n",
      "(array([0.99972954, 0.49386302]), array([0.96375839, 0.99268092]), array([0.98141447, 0.65958144]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9868636 , 0.34222846]), array([0.95596371, 0.64291996]), array([0.97116793, 0.446685  ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 140, Loss: 0.14062, Train Score: (0.9782196571233369, 0.7433978530274444), Val Score: (0.799441835068483, 0.49871781755520156), Time: 14.15700s\n",
      "(array([0.99963499, 0.48644499]), array([0.96276234, 0.99013158]), array([0.98085225, 0.65238005]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9867644 , 0.34002802]), array([0.95571296, 0.64028144]), array([0.97099049, 0.44417328]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 141, Loss: 0.14614, Train Score: (0.9764469605952377, 0.7384580129522165), Val Score: (0.7979972036207905, 0.4963437323564065), Time: 14.08300s\n",
      "(array([0.99978119, 0.4941542 ]), array([0.9637496 , 0.99407895]), array([0.9814348 , 0.66014964]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98679206, 0.33875465]), array([0.95539954, 0.64116095]), array([0.97084209, 0.44329583]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 142, Loss: 0.14353, Train Score: (0.9789142759388011, 0.7442184093091003), Val Score: (0.798280244566232, 0.4961316653435946), Time: 14.19100s\n",
      "(array([0.99974454, 0.4891049 ]), array([0.96304651, 0.99309211]), array([0.98105246, 0.65541384]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98696815, 0.33485194]), array([0.95423986, 0.64643799]), array([0.97032811, 0.44117647]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 143, Loss: 0.14606, Train Score: (0.9780693074917218, 0.7412173122087871), Val Score: (0.8003389296615513, 0.4967280402986902), Time: 14.13200s\n",
      "(array([0.99975993, 0.49443399]), array([0.96381113, 0.99350329]), array([0.98145646, 0.66027218]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98690727, 0.3410943 ]), array([0.95565028, 0.64423923]), array([0.9710273, 0.4460344]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 144, Loss: 0.14379, Train Score: (0.978657207388447, 0.7440803746686078), Val Score: (0.7999447528828779, 0.49878766575825434), Time: 14.14800s\n",
      "(array([0.99978151, 0.50417084]), array([0.96517337, 0.99407895]), array([0.98217267, 0.66902812]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98662872, 0.34159585]), array([0.9562928 , 0.63632366]), array([0.97122394, 0.44454685]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 145, Loss: 0.14144, Train Score: (0.9796261594125582, 0.7492267288869561), Val Score: (0.7963082304662708, 0.4952168450816363), Time: 14.15000s\n",
      "(array([0.9998029 , 0.50982128]), array([0.96593213, 0.99465461]), array([0.98257571, 0.6741166 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98649653, 0.34443114]), array([0.95710771, 0.63236588]), array([0.97157993, 0.44596061]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 146, Loss: 0.13543, Train Score: (0.9802933665897683, 0.7523298773315458), Val Score: (0.7947367919060999, 0.49472369367607805), Time: 14.23500s\n",
      "(array([0.99983005, 0.50416528]), array([0.9651265 , 0.99539474]), array([0.98217182, 0.66932095]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98667076, 0.33989686]), array([0.95586968, 0.63764292]), array([0.97102603, 0.44342508]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 147, Loss: 0.13605, Train Score: (0.980260617656437, 0.7498592136696371), Val Score: (0.7967562988033028, 0.49500428452173345), Time: 14.12900s\n",
      "(array([0.9997851 , 0.52294848]), array([0.96769279, 0.99416118]), array([0.98347721, 0.68537574]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98620146, 0.35629872]), array([0.95988153, 0.62313105]), array([0.97286351, 0.45336746]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 148, Loss: 0.13288, Train Score: (0.9809269893303825, 0.7586552538977653), Val Score: (0.7915062858713963, 0.4961989556617747), Time: 14.14900s\n",
      "(array([0.99982703, 0.50473331]), array([0.96520853, 0.9953125 ]), array([0.98221283, 0.66980271]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98631465, 0.34024797]), array([0.95663757, 0.62752858]), array([0.97124946, 0.44124923]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 149, Loss: 0.13260, Train Score: (0.98026051309807, 0.750103524679159), Val Score: (0.7920830771589149, 0.4902966920510496), Time: 14.16500s\n",
      "(array([0.99982114, 0.51203825]), array([0.9662163 , 0.99514803]), array([0.98273152, 0.67616573]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98602267, 0.34689349]), array([0.95848678, 0.61873351]), array([0.97205976, 0.44454976]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 150, Loss: 0.13111, Train Score: (0.9806821608546734, 0.7536765882703016), Val Score: (0.7886101452553921, 0.48937323385587045), Time: 14.15000s\n",
      "(array([0.99971248, 0.52238483]), array([0.96768401, 0.9921875 ]), array([0.98343754, 0.68442251]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98629652, 0.35717871]), array([0.95986585, 0.62576957]), array([0.97290171, 0.45477788]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 151, Loss: 0.13102, Train Score: (0.9799357528826886, 0.7574205318099351), Val Score: (0.7928177114454932, 0.4979128194112331), Time: 14.11200s\n",
      "(array([0.99972424, 0.51335602]), array([0.96648289, 0.99251645]), array([0.98282257, 0.67670311]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98605394, 0.34123911]), array([0.95734278, 0.62005277]), array([0.97148628, 0.4402123 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 152, Loss: 0.13518, Train Score: (0.9794996664347173, 0.7530649430004039), Val Score: (0.7886977741697541, 0.4871829755552608), Time: 14.22900s\n",
      "(array([0.99987523, 0.48655051]), array([0.96253384, 0.99662829]), array([0.98084926, 0.65387936]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9864503 , 0.32264574]), array([0.95265707, 0.63280563]), array([0.96925922, 0.42738343]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 153, Loss: 0.13502, Train Score: (0.9795810629552, 0.7416473878686979), Val Score: (0.7927313471220467, 0.4840433056244454), Time: 14.17400s\n",
      "(array([0.99982388, 0.50033074]), array([0.96459332, 0.99523026]), array([0.98189268, 0.66589634]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98669106, 0.33595558]), array([0.95502343, 0.63852243]), array([0.97059901, 0.44026683]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 154, Loss: 0.13512, Train Score: (0.9799117907068755, 0.74786253775601), Val Score: (0.7967729280015533, 0.49345826485168776), Time: 14.16600s\n",
      "(array([0.99982345, 0.48429309]), array([0.96224674, 0.99523026]), array([0.98067527, 0.6515384 ]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98690538, 0.32384734]), array([0.95196753, 0.64555849]), array([0.96912167, 0.4313207 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 155, Loss: 0.13608, Train Score: (0.9787385012779056, 0.7398437109771057), Val Score: (0.7987630081782714, 0.4908011213365303), Time: 14.15800s\n",
      "(array([0.99983558, 0.48269537]), array([0.96199187, 0.99555921]), array([0.98054872, 0.65016112]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98658481, 0.32085088]), array([0.95196753, 0.63676341]), array([0.96896708, 0.4266981 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 156, Loss: 0.13417, Train Score: (0.9787755390316287, 0.739203670001472), Val Score: (0.7943654707992037, 0.4850566709933013), Time: 14.21200s\n",
      "(array([0.99986623, 0.49304143]), array([0.96350352, 0.99638158]), array([0.98134815, 0.65966135]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98687154, 0.33371324]), array([0.95419285, 0.64379947]), array([0.97025711, 0.43957364]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 157, Loss: 0.13503, Train Score: (0.979942550140218, 0.7447737358088438), Val Score: (0.7989961615289611, 0.4948848288936819), Time: 14.15400s\n",
      "(array([0.99989351, 0.48832058]), array([0.96277992, 0.99712171]), array([0.98098581, 0.65558259]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98664008, 0.32894737]), array([0.95364436, 0.63764292]), array([0.96986166, 0.4340018 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 158, Loss: 0.12993, Train Score: (0.9799508150695726, 0.7427706490651482), Val Score: (0.7956436379767995, 0.4895295392901594), Time: 14.18100s\n",
      "(array([0.99987872, 0.51160827]), array([0.96610497, 0.99671053]), array([0.98270175, 0.67615063]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98628523, 0.3466407 ]), array([0.95793829, 0.62620932]), array([0.97190511, 0.44625509]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 159, Loss: 0.12967, Train Score: (0.9814077491838857, 0.7542159757303853), Val Score: (0.7920738046407854, 0.4928561233725406), Time: 14.16900s\n",
      "(array([0.99986656, 0.50993266]), array([0.96588818, 0.99638158]), array([0.98258371, 0.67461024]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98653123, 0.34582133]), array([0.95731144, 0.63324538]), array([0.97170171, 0.4473439 ]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 160, Loss: 0.12622, Train Score: (0.9811348817197205, 0.7532193528265287), Val Score: (0.7952784089591091, 0.4958434093489818), Time: 14.19200s\n",
      "(array([0.99989967, 0.49278719]), array([0.96343321, 0.99728618]), array([0.98132778, 0.65963176]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98675239, 0.33563854]), array([0.95483537, 0.64028144]), array([0.97053155, 0.44041137]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 161, Loss: 0.12714, Train Score: (0.9803596980323522, 0.7450833629840697), Val Score: (0.7975584078018878, 0.4941489917662598), Time: 14.15100s\n",
      "(array([0.99989697, 0.51569278]), array([0.96663815, 0.99720395]), array([0.98298632, 0.67982284]), array([341348,  12160], dtype=int64))\n",
      "(array([0.9864176 , 0.34986562]), array([0.95829873, 0.62972735]), array([0.97215488, 0.44981938]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 162, Loss: 0.12647, Train Score: (0.9819210498176578, 0.7564964525042918), Val Score: (0.7940130393037476, 0.496167071799138), Time: 14.19800s\n",
      "(array([0.99982424, 0.51451894]), array([0.96654734, 0.99523026]), array([0.98290421, 0.67834422]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98662515, 0.35218133]), array([0.95834574, 0.63544415]), array([0.97227986, 0.45319116]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 163, Loss: 0.12727, Train Score: (0.9808887995072786, 0.7549566367581528), Val Score: (0.7968949455190113, 0.5000849661690085), Time: 14.41600s\n",
      "(array([0.99989681, 0.5050606 ]), array([0.96518802, 0.99720395]), array([0.98223589, 0.67051895]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98639225, 0.34607013]), array([0.95762486, 0.6292876 ]), array([0.97179571, 0.44655953]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 164, Loss: 0.12466, Train Score: (0.9811959833166092, 0.7511803642563182), Val Score: (0.7934562299309939, 0.49405701533084273), Time: 14.48200s\n",
      "(array([0.9998361 , 0.50357737]), array([0.96503861, 0.99555921]), array([0.98212923, 0.66883978]), array([341348,  12160], dtype=int64))\n",
      "(array([0.98686998, 0.34464875]), array([0.95643384, 0.64291996]), array([0.97141356, 0.44874156]), array([63811,  2274], dtype=int64))\n",
      "Epoch: 165, Loss: 0.12547, Train Score: (0.9802989110742363, 0.7496446681252796), Val Score: (0.799676904257181, 0.499927960640136), Time: 14.33600s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 6\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m201\u001B[39m):\n\u001B[0;32m      5\u001B[0m     s \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 6\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m     train_score \u001B[38;5;241m=\u001B[39m evaluate(model, train_dl)\n\u001B[0;32m      8\u001B[0m     val_score \u001B[38;5;241m=\u001B[39m evaluate(model, val_dl)\n",
      "Cell \u001B[1;32mIn[6], line 8\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, loader, criterion, optimizer)\u001B[0m\n\u001B[0;32m      6\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 8\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m label \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39my\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, label\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\Projects\\CxC Cyclica\\LigandGNNV2.py:35\u001B[0m, in \u001B[0;36mLigandGNNV2.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     32\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mconv(x, edge_index)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m---> 35\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mact(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnorm(x))\n\u001B[0;32m     38\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(x, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\models\\deepgcn.py:82\u001B[0m, in \u001B[0;36mDeepGCNLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     80\u001B[0m         h \u001B[38;5;241m=\u001B[39m checkpoint(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv, h, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     81\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m---> 82\u001B[0m         h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(h, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     84\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x \u001B[38;5;241m+\u001B[39m h\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\gen_conv.py:158\u001B[0m, in \u001B[0;36mGENConv.forward\u001B[1;34m(self, x, edge_index, edge_attr, size)\u001B[0m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m x[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m edge_attr\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[1;32m--> 158\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg_norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg_norm(x[\u001B[38;5;241m0\u001B[39m], out)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:391\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    389\u001B[0m         aggr_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate(out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maggr_kwargs)\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    394\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (aggr_kwargs, ), out)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:514\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[1;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Tensor, index: Tensor,\n\u001B[0;32m    502\u001B[0m               ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    503\u001B[0m               dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    504\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;124;03m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[0;32m    506\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:109\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dim_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    108\u001B[0m         dim_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 109\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dim_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered invalid \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    111\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    112\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>= \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax())\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(x, index, ptr, dim_size, dim, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_hist = []\n",
    "val_hist = []\n",
    "\n",
    "for epoch in range(1, 201):\n",
    "    s = time.time()\n",
    "    loss = train(model, train_dl, criterion, optimizer)\n",
    "    train_score = evaluate(model, train_dl)\n",
    "    val_score = evaluate(model, val_dl)\n",
    "    scheduler.step(loss)\n",
    "    e = time.time()\n",
    "\n",
    "    train_hist.append(train_score)\n",
    "    val_hist.append(val_score)\n",
    "\n",
    "    if sum(val_score) > (.77 + .44) and sum(val_score) >= np.asarray(val_hist).sum(axis=1).max():\n",
    "        print(\"saving...\")\n",
    "        torch.save(model.state_dict(), './models/BestModel2.pt')\n",
    "\n",
    "    # print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}, Train Score: {train_score:.05f}, Val Score: {val_score:.05f}, Time: {e - s:.05f}s')\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}, Train Score: {train_score}, Val Score: {val_score}, Time: {e - s:.05f}s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_hist)\n",
    "plt.plot(train_hist)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.98008844, 0.35144268]), array([0.96662341, 0.47943262]), array([0.97330936, 0.40557972]), array([74753,  2820], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7230280186103207, 0.4248997084581403)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.98735333, 0.18360138]), array([0.88251977, 0.70035461]), array([0.93199782, 0.2909332 ]), array([74753,  2820], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7914371875110588, 0.44742447555662)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('./models/BestModel2.pt'))\n",
    "evaluate(model, test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "data = test_dl.dataset[4].to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "pred = model(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.sigmoid(pred).round()\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(65., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "403\n"
     ]
    }
   ],
   "source": [
    "print(out.sum())\n",
    "print(len(out))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(17.5217, device='cuda:0')"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y) / data.y.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(23., device='cuda:0')"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "0.38636363636363635"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(data.y.detach().cpu().numpy(), out.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/modelBest.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
