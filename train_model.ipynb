{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Next steps:\n",
    "1. Add a \"master node\" that connects all nodes together, so that message passing works between all nodes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from EmbedDataset import LigandBinaryDataset\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch_geometric.loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "dataset = LigandBinaryDataset('./data2/')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle()\n",
    "train_dataset = dataset[:int(len(dataset) * 0.7)]\n",
    "val_dataset = dataset[int(len(dataset) * 0.7):int(len(dataset) * 0.85)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.85):]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_dl = DataLoader(train_dataset, batch_size=16)\n",
    "val_dl = DataLoader(val_dataset, batch_size=16)\n",
    "test_dl = DataLoader(test_dataset, batch_size=16)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from LigandGNNV2 import LigandGNNV2\n",
    "from LigandGNNV1 import LigandGNNV1\n",
    "\n",
    "device = torch.device('cuda')\n",
    "# model = LigandGNNV1(dataset.num_node_features, 1).to(device)\n",
    "model = LigandGNNV2(256, 30, dataset[0]).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min')\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=torch.FloatTensor([20]).to(device))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(model, loader, criterion, optimizer):\n",
    "    model.train()\n",
    "\n",
    "    loss_acc = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        label = data.y\n",
    "\n",
    "        loss = criterion(output, label.reshape(-1, 1))\n",
    "        loss.backward()\n",
    "        loss_acc += data.num_graphs * loss.item()\n",
    "        optimizer.step()\n",
    "\n",
    "    return loss_acc / len(loader.dataset)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_recall_curve, roc_curve, auc, precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    preds = np.asarray([])\n",
    "    labels = np.asarray([])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            pred = torch.sigmoid(model(data).round().squeeze().cpu()).round().numpy()\n",
    "            label = data.y.cpu().numpy()\n",
    "\n",
    "            preds = np.concatenate([preds, pred])\n",
    "            labels = np.concatenate([labels, label])\n",
    "\n",
    "    precision, recall, _ = precision_recall_curve(labels, preds)\n",
    "    fpr, tpr, thresholds = roc_curve(labels, preds, pos_label=1)\n",
    "    print(precision_recall_fscore_support(labels, preds))\n",
    "    return auc(fpr, tpr), auc(recall, precision)\n",
    "    return roc_auc_score(labels, preds)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.98272913, 0.07346837]), array([0.69897149, 0.66022878]), array([0.81691073, 0.13222331]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98530892, 0.07258788]), array([0.71870538, 0.67262152]), array([0.83115127, 0.13103476]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 001, Loss: 1.11332, Train Score: (0.6796001340031849, 0.37277626896230887), Val Score: (0.6956634494781304, 0.37779286850868826), Time: 21.99421s\n",
      "(array([0.97698832, 0.11502621]), array([0.88160426, 0.42564655]), array([0.92684871, 0.18110958]), array([333686,  12064], dtype=int64))\n",
      "(array([0.97968651, 0.11289632]), array([0.88737336, 0.43788949]), array([0.93124781, 0.1795112 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 002, Loss: 0.97524, Train Score: (0.6536254072071058, 0.28035662595604227), Val Score: (0.6626314243075565, 0.2843010162515261), Time: 16.88200s\n",
      "(array([0.98334467, 0.10199635]), array([0.80116337, 0.62466844]), array([0.88295453, 0.17535981]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98576101, 0.10029862]), array([0.81153192, 0.64187786]), array([0.89020161, 0.17348829]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 003, Loss: 0.93947, Train Score: (0.712915902084348, 0.36988047421842835), Val Score: (0.7267048899132025, 0.37676362383891215), Time: 16.83600s\n",
      "(array([0.98354817, 0.12591855]), array([0.84743142, 0.6079244 ]), array([0.91043027, 0.20862491]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98528049, 0.11965812]), array([0.85292718, 0.61071874]), array([0.91433903, 0.2001089 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 004, Loss: 0.88156, Train Score: (0.7276779103716227, 0.37376167882501976), Val Score: (0.7318229572757704, 0.37135761008153917), Time: 16.91800s\n",
      "(array([0.98704337, 0.10894272]), array([0.78900523, 0.71352785]), array([0.87698319, 0.18902479]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98917745, 0.10947906]), array([0.80542599, 0.73078521]), array([0.88789446, 0.19042979]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 005, Loss: 0.88531, Train Score: (0.7512665419614696, 0.4162331160379564), Val Score: (0.7681055987148384, 0.4243985469700663), Time: 16.80800s\n",
      "(array([0.98577867, 0.14142565]), array([0.85543595, 0.65865385]), array([0.91599372, 0.23285323]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9872915 , 0.13560044]), array([0.86207928, 0.66098878]), array([0.92044663, 0.22503536]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 006, Loss: 0.83452, Train Score: (0.7570448974600257, 0.40599491670478105), Val Score: (0.7615340323458226, 0.4036671340902921), Time: 17.29100s\n",
      "(array([0.98867328, 0.12155855]), array([0.80541587, 0.74477785]), array([0.88768515, 0.20900452]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99002016, 0.12051746]), array([0.82156796, 0.74698795]), array([0.89796222, 0.20754935]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 007, Loss: 0.82092, Train Score: (0.775096860734208, 0.43762083840942867), Val Score: (0.7842779563211028, 0.4377623453165052), Time: 17.05100s\n",
      "(array([0.98868811, 0.10737093]), array([0.77295721, 0.75538793]), array([0.86761347, 0.18801708]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98952852, 0.09736899]), array([0.7723261 , 0.75031159]), array([0.8675389 , 0.17236936]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 008, Loss: 0.77563, Train Score: (0.7641725711524793, 0.43564696302001743), Val Score: (0.7613188472042556, 0.42779725704042365), Time: 16.99000s\n",
      "(array([0.99041724, 0.11789096]), array([0.78641597, 0.78953912]), array([0.87670574, 0.20514974]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99034462, 0.1092597 ]), array([0.79645067, 0.76277524]), array([0.88287745, 0.19114049]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 009, Loss: 0.76723, Train Score: (0.7879775482850816, 0.45738676976093867), Val Score: (0.77961295431784, 0.4397769174787855), Time: 16.95300s\n",
      "(array([0.99125997, 0.11541048]), array([0.77528575, 0.81092507]), array([0.87007058, 0.20206339]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99072715, 0.10371028]), array([0.7802271 , 0.77690071]), array([0.87296685, 0.18299247]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 010, Loss: 0.73766, Train Score: (0.7931054069959764, 0.4664663983985704), Val Score: (0.7785639045067806, 0.4438410844620035), Time: 16.98800s\n",
      "(array([0.99125328, 0.11542637]), array([0.77536666, 0.81075928]), array([0.87011895, 0.2020826 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99039395, 0.1014231 ]), array([0.77674577, 0.76983797]), array([0.87065477, 0.17923296]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 011, Loss: 0.71102, Train Score: (0.7930629729455784, 0.46639434687587816), Val Score: (0.7732918699508293, 0.43927805575355144), Time: 17.03000s\n",
      "(array([0.99187158, 0.12168066]), array([0.78549894, 0.8219496 ]), array([0.87670417, 0.21197999]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99084905, 0.10961798]), array([0.79366288, 0.7760698 ]), array([0.88136156, 0.19210202]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 012, Loss: 0.69613, Train Score: (0.8037242721206269, 0.4749214196184049), Val Score: (0.7848663390240421, 0.44639264919275906), Time: 16.96000s\n",
      "(array([0.99116832, 0.14404046]), array([0.82905486, 0.79567308]), array([0.90289248, 0.24392351]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98976636, 0.12838915]), array([0.83649963, 0.73577067]), array([0.90670165, 0.21862848]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 013, Loss: 0.67603, Train Score: (0.8123639684406206, 0.4734214806382461), Val Score: (0.7861351474554241, 0.43626731797208457), Time: 17.01900s\n",
      "(array([0.99195091, 0.14512746]), array([0.82654352, 0.81448939]), array([0.90172462, 0.24635828]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99003429, 0.12929351]), array([0.83625484, 0.7428334 ]), array([0.90667021, 0.22025129]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 014, Loss: 0.65709, Train Score: (0.8205164534397409, 0.4830448689035335), Val Score: (0.7895441236038143, 0.440138936758061), Time: 16.98500s\n",
      "(array([0.99072025, 0.16839155]), array([0.86129475, 0.77685676]), array([0.92148514, 0.27678677]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98844597, 0.14204061]), array([0.86323519, 0.69173245]), array([0.9216072 , 0.23568547]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 015, Loss: 0.63365, Train Score: (0.8190757570400329, 0.47651714226514924), Val Score: (0.777483820577372, 0.421771834425321), Time: 17.00700s\n",
      "(array([0.99065608, 0.18070536]), array([0.87343491, 0.77213196]), array([0.92835983, 0.29286927]), array([333686,  12064], dtype=int64))\n",
      "(array([0.988003 , 0.1543439]), array([0.87914598, 0.67386789]), array([0.93040124, 0.25116135]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 016, Loss: 0.62895, Train Score: (0.8227834343671557, 0.48039407819154806), Val Score: (0.7765069351197942, 0.41927430852465375), Time: 17.06100s\n",
      "(array([0.99269843, 0.16541802]), array([0.84910365, 0.82725464]), array([0.91530341, 0.27570584]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98958038, 0.13963532]), array([0.85370232, 0.7253843 ]), array([0.91663321, 0.23418952]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 017, Loss: 0.62011, Train Score: (0.8381791451249353, 0.49935006934895854), Val Score: (0.789543307213845, 0.4368618117291455), Time: 16.97000s\n",
      "(array([0.99199959, 0.18761712]), array([0.87397434, 0.80503979]), array([0.92925434, 0.30431309]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98843231, 0.1547686 ]), array([0.87731012, 0.68633153]), array([0.92956204, 0.25258008]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 018, Loss: 0.59615, Train Score: (0.8395070614759081, 0.49972975332356345), Val Score: (0.7818208287296048, 0.4255209636531099), Time: 17.04500s\n",
      "(array([0.9930879 , 0.18819804]), array([0.87017436, 0.83247679]), array([0.92757702, 0.30699395]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98844162, 0.15209999]), array([0.87453594, 0.6875779 ]), array([0.92800658, 0.24909693]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 019, Loss: 0.57360, Train Score: (0.8513255729913879, 0.5132600452495854), Val Score: (0.7810569165335042, 0.42479009123179723), Time: 17.03200s\n",
      "(array([0.99294289, 0.19467784]), array([0.87620398, 0.82775199]), array([0.93092793, 0.31521962]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98794243, 0.15513768]), array([0.8802475 , 0.67179061]), array([0.93099084, 0.25206547]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 020, Loss: 0.56315, Train Score: (0.8519779827915539, 0.5142199780777678), Val Score: (0.7760190559543233, 0.41866548136888154), Time: 17.10500s\n",
      "(array([0.99445857, 0.16762498]), array([0.84382024, 0.86994363]), array([0.91296735, 0.28108846]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98898438, 0.13410142]), array([0.84975862, 0.71084337]), array([0.91410056, 0.22563629]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 021, Loss: 0.56081, Train Score: (0.856881936070126, 0.5210532874709198), Val Score: (0.7803009959194908, 0.4270548405473411), Time: 17.24000s\n",
      "(array([0.99402289, 0.1778928 ]), array([0.85672758, 0.85750995]), array([0.92028271, 0.29465799]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98856085, 0.14304047]), array([0.86377915, 0.69464063]), array([0.92196708, 0.23723042]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 022, Loss: 0.54830, Train Score: (0.8571187645838078, 0.5201872737054776), Val Score: (0.7792098921379358, 0.4236797678474316), Time: 17.16600s\n",
      "(array([0.99350553, 0.1804987 ]), array([0.86142062, 0.84424735]), array([0.92276035, 0.29741134]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98915043, 0.15170389]), array([0.87034745, 0.70835064]), array([0.92595379, 0.24989008]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 023, Loss: 0.57058, Train Score: (0.8528339822336668, 0.515090303728689), Val Score: (0.7893490487743289, 0.43464921442969606), Time: 17.15400s\n",
      "(array([0.9920524 , 0.23514779]), array([0.90601344, 0.7992374 ]), array([0.94708285, 0.36338283]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98793781, 0.19934682]), array([0.91332019, 0.65932696]), array([0.94916476, 0.30613426]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 024, Loss: 0.56483, Train Score: (0.8526254191566649, 0.5206951262252821), Val Score: (0.7863235753451246, 0.43473574639805423), Time: 17.05800s\n",
      "(array([0.99491684, 0.15328425]), array([0.8235347 , 0.88362069]), array([0.90114971, 0.2612489 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99009723, 0.12290045]), array([0.82530768, 0.74781886]), array([0.90022324, 0.21110655]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 025, Loss: 0.56500, Train Score: (0.8535776949711344, 0.5204828394395274), Val Score: (0.7865632691350438, 0.43935612713526756), Time: 17.17900s\n",
      "(array([0.99530185, 0.18812925]), array([0.8615285 , 0.88751658]), array([0.9235964 , 0.31045131]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99013831, 0.16138171]), array([0.87520228, 0.73369339]), array([0.92912931, 0.26456929]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 026, Loss: 0.53597, Train Score: (0.874522540546664, 0.5397853146569981), Val Score: (0.8044478394465453, 0.45175787577148896), Time: 18.04500s\n",
      "(array([0.99511283, 0.1769056 ]), array([0.85123739, 0.88436671]), array([0.91756942, 0.29483371]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99029852, 0.15215352]), array([0.86481267, 0.74117158]), array([0.92331146, 0.25247665]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 027, Loss: 0.54291, Train Score: (0.8678020508579111, 0.5326535104229334), Val Score: (0.8029921285600077, 0.45076436504613954), Time: 17.16400s\n",
      "(array([0.99487458, 0.19344214]), array([0.86789976, 0.87632626]), array([0.92705959, 0.31692548]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9890263 , 0.14982794]), array([0.86897396, 0.70544246]), array([0.92512161, 0.24716157]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 028, Loss: 0.50054, Train Score: (0.8721130109993493, 0.5370418298246439), Val Score: (0.7872082087361691, 0.4323032339372948), Time: 17.24900s\n",
      "(array([0.99558362, 0.19834361]), array([0.86946411, 0.89331897]), array([0.92825959, 0.32461332]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98930087, 0.15711662]), array([0.87517509, 0.71084337]), array([0.92874512, 0.25735128]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 029, Loss: 0.47540, Train Score: (0.881391536246031, 0.5476924586710878), Val Score: (0.7930092300936935, 0.4385624416205964), Time: 17.23000s\n",
      "(array([0.99584064, 0.20226332]), array([0.87176867, 0.89928714]), array([0.92968338, 0.3302487 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98870963, 0.15079222]), array([0.87172095, 0.695887  ]), array([0.92653701, 0.24787273]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 030, Loss: 0.46619, Train Score: (0.8855279020134894, 0.5525322779208194), Val Score: (0.7838039727343828, 0.4281590765298543), Time: 17.24100s\n",
      "(array([0.99472118, 0.21878389]), array([0.88772679, 0.86969496]), array([0.93818332, 0.34961679]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98824312, 0.16676904]), array([0.88931801, 0.67677607]), array([0.93617448, 0.26759754]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 031, Loss: 0.48749, Train Score: (0.8787108726368034, 0.5465127415921811), Val Score: (0.783047040813764, 0.4268948859820971), Time: 17.21200s\n",
      "(array([0.99628075, 0.20936445]), array([0.87581739, 0.90956565]), array([0.93217336, 0.34037999]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98990345, 0.16971584]), array([0.88397362, 0.72455339]), array([0.93394444, 0.2750138 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 032, Loss: 0.47190, Train Score: (0.8926915175369128, 0.5610427777044986), Val Score: (0.8042635019813277, 0.45149978777081673), Time: 17.17200s\n",
      "(array([0.9952105 , 0.21876156]), array([0.88611749, 0.88204576]), array([0.93750099, 0.3505749 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98857134, 0.1729276 ]), array([0.89281295, 0.68466971]), array([0.9382552 , 0.27611628]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 033, Loss: 0.47689, Train Score: (0.8840816218330927, 0.5524615052882161), Val Score: (0.7887413297760953, 0.4337958899307754), Time: 17.21700s\n",
      "(array([0.99618625, 0.19932678]), array([0.86812452, 0.90807361]), array([0.92775703, 0.32689783]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99010657, 0.16842206]), array([0.88189298, 0.73078521]), array([0.93287205, 0.27375302]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 034, Loss: 0.49439, Train Score: (0.8880990658401978, 0.5553039552131789), Val Score: (0.8063390929692751, 0.45387004900111744), Time: 17.19500s\n",
      "(array([0.99752301, 0.15983601]), array([0.82067273, 0.94363395]), array([0.90049703, 0.27336799]), array([333686,  12064], dtype=int64))\n",
      "(array([0.99120235, 0.13723318]), array([0.84115047, 0.77191525]), array([0.91003251, 0.2330365 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 035, Loss: 0.52136, Train Score: (0.8821533402540749, 0.5527183496295011), Val Score: (0.8065328598798823, 0.45818881332703243), Time: 17.28100s\n",
      "(array([0.99657365, 0.19012562]), array([0.85857063, 0.91835212]), array([0.92243916, 0.31503071]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98929748, 0.15557979]), array([0.8736384 , 0.71125883]), array([0.92787764, 0.2553128 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 036, Loss: 0.50284, Train Score: (0.8884613771434862, 0.5556633095281742), Val Score: (0.792448615949226, 0.4379951693174837), Time: 17.20300s\n",
      "(array([0.99732789, 0.17192082]), array([0.83665782, 0.93799735]), array([0.90995494, 0.29058227]), array([333686,  12064], dtype=int64))\n",
      "(array([0.990572  , 0.14342314]), array([0.85299517, 0.75197341]), array([0.91665023, 0.24089971]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 037, Loss: 0.49318, Train Score: (0.8873275817553729, 0.5560407879479341), Val Score: (0.8024842916259096, 0.4516289056518861), Time: 17.26200s\n",
      "(array([0.99530854, 0.24126603]), array([0.89963918, 0.88270889]), array([0.94505885, 0.37895449]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9881811, 0.2005   ]), array([0.91302101, 0.6663897 ]), array([0.9491154 , 0.30825406]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 038, Loss: 0.49425, Train Score: (0.8911740338436788, 0.5640337338178723), Val Score: (0.7897053535605577, 0.4387317778577811), Time: 17.10900s\n",
      "(array([0.99660875, 0.20141086]), array([0.86836727, 0.91826923]), array([0.92807887, 0.33036114]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98871698, 0.15843934]), array([0.87944516, 0.69339427]), array([0.93088533, 0.25793988]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 039, Loss: 0.45965, Train Score: (0.8933182491001445, 0.561265930033714), Val Score: (0.7864197144448679, 0.4307757743224104), Time: 17.18300s\n",
      "(array([0.99541321, 0.24994146]), array([0.90400556, 0.88478117]), array([0.94750993, 0.38977542]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98782726, 0.20130119]), array([0.91485687, 0.65558787]), array([0.94994281, 0.30802264]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 040, Loss: 0.43767, Train Score: (0.8943933646120177, 0.569371436583744), Val Score: (0.7852223697970289, 0.4339026403163008), Time: 17.15400s\n",
      "(array([0.99611103, 0.20762929]), array([0.87506518, 0.90550398]), array([0.9316729 , 0.33780169]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98992397, 0.17355372]), array([0.88712858, 0.72413793]), array([0.93571152, 0.28      ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 041, Loss: 0.45725, Train Score: (0.8902845799091511, 0.5582152259818517), Val Score: (0.8056332546312687, 0.4532175824151742), Time: 17.18300s\n",
      "(array([0.99708264, 0.1865057 ]), array([0.85319432, 0.93095159]), array([0.91954368, 0.3107551 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98929039, 0.14583687]), array([0.86300401, 0.71458247]), array([0.9218422 , 0.24223646]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 042, Loss: 0.47429, Train Score: (0.8920729559604718, 0.5599332713627339), Val Score: (0.7887932397486773, 0.4347328557520075), Time: 17.39500s\n",
      "(array([0.99682432, 0.22642047]), array([0.88612348, 0.92191645]), array([0.93821978, 0.36355316]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98915789, 0.17856386]), array([0.89452642, 0.700457  ]), array([0.93946513, 0.28458098]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 043, Loss: 0.43372, Train Score: (0.9040199634900334, 0.5755307147249291), Val Score: (0.7974917082039198, 0.44425747579842045), Time: 17.11500s\n",
      "(array([0.9972875 , 0.20277998]), array([0.86713557, 0.93476459]), array([0.9276687 , 0.33326438]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98917822, 0.15641073]), array([0.87509349, 0.70751973]), array([0.92864513, 0.25618654]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 044, Loss: 0.43368, Train Score: (0.9009500797128787, 0.5699103877697382), Val Score: (0.7913066135016946, 0.4366003470305292), Time: 17.24700s\n",
      "(array([0.99699209, 0.241592  ]), array([0.89498211, 0.92531499]), array([0.94323705, 0.38314742]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98848838, 0.19301362]), array([0.90732304, 0.67719152]), array([0.94616825, 0.30040546]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 045, Loss: 0.40851, Train Score: (0.910148547833077, 0.5847564584578893), Val Score: (0.7922572840841329, 0.4402183173497495), Time: 17.14600s\n",
      "(array([0.99652439, 0.21126329]), array([0.87643473, 0.91545093]), array([0.93262963, 0.34330121]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98937571, 0.17279822]), array([0.88900524, 0.70835064]), array([0.93650885, 0.27782304]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 046, Loss: 0.46642, Train Score: (0.895942830217725, 0.5648321658308175), Val Score: (0.7986779397786126, 0.44519637844479193), Time: 17.14700s\n",
      "(array([0.99722817, 0.22053374]), array([0.88087004, 0.93227785]), array([0.9354446 , 0.35669093]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98976824, 0.18037578]), array([0.89322092, 0.71790611]), array([0.93901942, 0.28831234]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 047, Loss: 0.43898, Train Score: (0.9065739454785484, 0.5775872832227924), Val Score: (0.8055635111989071, 0.45361146200766583), Time: 17.22800s\n",
      "(array([0.99607722, 0.23183347]), array([0.89184443, 0.90285146]), array([0.94108346, 0.3689327 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98828061, 0.18104699]), array([0.90022438, 0.67386789]), array([0.94219958, 0.28541263]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 048, Loss: 0.44414, Train Score: (0.8973479437402443, 0.5690373297441647), Val Score: (0.7870461341406686, 0.4326258565963182), Time: 17.15500s\n",
      "(array([0.99543405, 0.2431344 ]), array([0.90031047, 0.88577586]), array([0.94548573, 0.38154066]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98737468, 0.18068934]), array([0.9039913 , 0.64686332]), array([0.94384495, 0.2824746 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 049, Loss: 0.41731, Train Score: (0.8930431667950481, 0.5664479002126741), Val Score: (0.7754273059958702, 0.41937270136466387), Time: 17.27100s\n",
      "(array([0.99592061, 0.28010675]), array([0.9167331 , 0.89613727]), array([0.9546876 , 0.42680616]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98799849, 0.22462326]), array([0.92583124, 0.65641878]), array([0.95590517, 0.33471031]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 050, Loss: 0.43330, Train Score: (0.9064351821442674, 0.5899340102510885), Val Score: (0.7911250076942636, 0.4459659633370347), Time: 17.13900s\n",
      "(array([0.99640397, 0.24936404]), array([0.90095779, 0.910063  ]), array([0.94628019, 0.39146402]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98792053, 0.19506203]), array([0.91088597, 0.65974242]), array([0.94784061, 0.30109973]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 051, Loss: 0.42267, Train Score: (0.905510392004596, 0.5812825719899319), Val Score: (0.785314195306865, 0.43279449787003144), Time: 17.15600s\n",
      "(array([0.99602908, 0.28899731]), array([0.92007756, 0.89854111]), array([0.95654802, 0.43733484]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98715101, 0.21542817]), array([0.92462093, 0.63232239]), array([0.95486335, 0.32136824]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 052, Loss: 0.39629, Train Score: (0.9093093360010255, 0.5955392757615554), Val Score: (0.778471660914884, 0.42970209522151503), Time: 17.18600s\n",
      "(array([0.99726741, 0.25220435]), array([0.90011568, 0.9317805 ]), array([0.94620431, 0.39696301]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9892521 , 0.19615385]), array([0.90620793, 0.69921064]), array([0.94591084, 0.30636206]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 053, Loss: 0.40519, Train Score: (0.9159480907959325, 0.5931825923538897), Val Score: (0.8027092819217447, 0.45244903661245667), Time: 17.13000s\n",
      "(array([0.99633157, 0.26881985]), array([0.91078439, 0.90724469]), array([0.95163929, 0.41474829]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98745625, 0.19571788]), array([0.913157  , 0.64561695]), array([0.94885436, 0.30037692]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 054, Loss: 0.38359, Train Score: (0.9090145425377351, 0.5896504913711769), Val Score: (0.7793869753144296, 0.426283545443682), Time: 17.20700s\n",
      "(array([0.99418497, 0.31424101]), array([0.93301187, 0.84905504]), array([0.96262754, 0.45871026]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98646118, 0.24353628]), array([0.93832869, 0.60656419]), array([0.96179312, 0.3475363 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 055, Loss: 0.40858, Train Score: (0.8910334566128505, 0.5842814311173197), Val Score: (0.7724464374027059, 0.43128525547332525), Time: 17.18800s\n",
      "(array([0.99516587, 0.31042696]), array([0.92972135, 0.87508289]), array([0.96133109, 0.45828269]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98661158, 0.22796728]), array([0.93197797, 0.61362692]), array([0.9585169 , 0.33243304]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 056, Loss: 0.38826, Train Score: (0.9024021230266495, 0.5949342451228602), Val Score: (0.7728024455766621, 0.4269201941301545), Time: 17.13800s\n",
      "(array([0.99534925, 0.25025251]), array([0.9043442 , 0.88312334]), array([0.94766692, 0.38999213]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98670729, 0.1687806 ]), array([0.89840212, 0.63024512]), array([0.94048644, 0.26625713]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 057, Loss: 0.38756, Train Score: (0.8937337730037058, 0.5687269703695677), Val Score: (0.7643236199217118, 0.40537259243863905), Time: 17.15300s\n",
      "(array([0.9960544 , 0.29076531]), array([0.92070989, 0.89912135]), array([0.95690132, 0.43942555]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9881199 , 0.22936841]), array([0.92749031, 0.65932696]), array([0.95684563, 0.34033884]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 058, Loss: 0.37999, Train Score: (0.9099156208613252, 0.5967032750276736), Val Score: (0.7934086368804478, 0.44974654145421744), Time: 17.14600s\n",
      "(array([0.99499495, 0.3292748 ]), array([0.93594577, 0.86977785]), array([0.96456748, 0.47770367]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98703672, 0.25415395]), array([0.94017815, 0.62276693]), array([0.96303777, 0.36098736]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 059, Loss: 0.42983, Train Score: (0.9028618104174431, 0.6017981976602473), Val Score: (0.7814725381244935, 0.4444386866964877), Time: 17.15400s\n",
      "(array([0.99596523, 0.30501876]), array([0.92617311, 0.89622016]), array([0.95980211, 0.45513671]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98722229, 0.23565002]), array([0.93299789, 0.63107603]), array([0.95934448, 0.34316051]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 060, Loss: 0.39269, Train Score: (0.9111966340010147, 0.6024300165376895), Val Score: (0.7820369602055652, 0.4392095889992262), Time: 17.18900s\n",
      "(array([0.99270139, 0.38268739]), array([0.95298274, 0.80620027]), array([0.97243666, 0.51901065]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98521394, 0.29448922]), array([0.95595295, 0.56169506]), array([0.97036291, 0.38639611]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 061, Loss: 0.39858, Train Score: (0.8795915047542829, 0.5978248829705641), Val Score: (0.7588240018311995, 0.4350382274982897), Time: 17.15600s\n",
      "(array([0.99491146, 0.30240342]), array([0.92754266, 0.86878316]), array([0.96004665, 0.44864414]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98560785, 0.19629014]), array([0.9210444 , 0.58911508]), array([0.95223299, 0.29446579]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 062, Loss: 0.38304, Train Score: (0.8981629081822677, 0.5878825126389859), Val Score: (0.7550797408196313, 0.39921416077598676), Time: 17.12100s\n",
      "(array([0.99368868, 0.37074052]), array([0.9488651, 0.8333057]), array([0.97075975, 0.51316998]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98636447, 0.27886289]), array([0.94928945, 0.599086  ]), array([0.9674719 , 0.38057535]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 063, Loss: 0.36356, Train Score: (0.8910854018206031, 0.6049312832028717), Val Score: (0.774187726585293, 0.4453279771387647), Time: 17.17300s\n",
      "(array([0.99467113, 0.37979924]), array([0.94926668, 0.85933355]), array([0.97143865, 0.52677846]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98586274, 0.28493095]), array([0.95211804, 0.58288326]), array([0.9686966 , 0.38275815]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 064, Loss: 0.37805, Train Score: (0.9043001151168005, 0.6220204815018868), Val Score: (0.7675006480978156, 0.440517411673224), Time: 17.09700s\n",
      "(array([0.99513558, 0.33522131]), array([0.93739024, 0.87325928]), array([0.96540017, 0.48446805]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98743252, 0.25793919]), array([0.94025974, 0.63439967]), array([0.96326895, 0.36675874]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 065, Loss: 0.37332, Train Score: (0.9053247624722592, 0.6064514303830545), Val Score: (0.7873297039479008, 0.4519633237538067), Time: 17.16400s\n",
      "(array([0.99518085, 0.35964373]), array([0.9437645 , 0.87359085]), array([0.96879095, 0.50952427]), array([333686,  12064], dtype=int64))\n",
      "(array([0.986779  , 0.26044053]), array([0.94292514, 0.61404238]), array([0.96435376, 0.36575105]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 066, Loss: 0.36368, Train Score: (0.9086776729841844, 0.6188226424119629), Val Score: (0.778483757045848, 0.4433579624863944), Time: 17.16300s\n",
      "(array([0.99542387, 0.32607429]), array([0.93415367, 0.88121684]), array([0.96381601, 0.47601137]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98719881, 0.24197413]), array([0.93545931, 0.62941421]), array([0.96063289, 0.34956161]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 067, Loss: 0.37252, Train Score: (0.9076852544616549, 0.6057178721516826), Val Score: (0.7824367568255921, 0.4415670700536361), Time: 17.18400s\n",
      "(array([0.99594196, 0.27100183]), array([0.91275031, 0.89713196]), array([0.95253315, 0.41626123]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98869907, 0.20531129]), array([0.91372816, 0.68093062]), array([0.94973638, 0.31549567]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 068, Loss: 0.38919, Train Score: (0.9049411365182799, 0.5858615446849029), Val Score: (0.7973293878439648, 0.4481774432353833), Time: 17.26000s\n",
      "(array([0.99739399, 0.255511  ]), array([0.90152119, 0.93484748]), array([0.94703737, 0.40133089]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98936375, 0.2023253 ]), array([0.90949888, 0.70128791]), array([0.94775178, 0.31404651]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 069, Loss: 0.39268, Train Score: (0.9181843353432333, 0.5963158991605514), Val Score: (0.8053933941735011, 0.45654048230795635), Time: 17.11800s\n",
      "(array([0.99690639, 0.27172107]), array([0.91067351, 0.92183355]), array([0.95184085, 0.41972373]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98896098, 0.21163683]), array([0.91616237, 0.6875779 ]), array([0.95117079, 0.32365308]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 070, Loss: 0.38342, Train Score: (0.916253530902899, 0.5981410148598875), Val Score: (0.8018701347289214, 0.4545585101492138), Time: 17.18000s\n",
      "(array([0.9972962 , 0.25590972]), array([0.9019887 , 0.93236074]), array([0.94725115, 0.40159237]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98934841, 0.19387755]), array([0.90438567, 0.70253428]), array([0.9449611 , 0.30389074]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 071, Loss: 0.35955, Train Score: (0.9171747193326225, 0.5953152756108486), Val Score: (0.8034599708602455, 0.45292003696247213), Time: 17.17500s\n",
      "(array([0.99651741, 0.30339685]), array([0.92440798, 0.91064324]), array([0.95910924, 0.45515184]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9882573 , 0.22935516]), array([0.92702795, 0.66348151]), array([0.95666391, 0.34087513]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 072, Loss: 0.33208, Train Score: (0.9175256062176403, 0.6085789737489656), Val Score: (0.7952547290660168, 0.45175135493286456), Time: 17.18900s\n",
      "(array([0.9967355, 0.2784979]), array([0.91409289, 0.91719164]), array([0.95362706, 0.42726132]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98888351, 0.21263701]), array([0.91696471, 0.68508517]), array([0.95156715, 0.32454241]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 073, Loss: 0.34572, Train Score: (0.9156422671425039, 0.5992894569308019), Val Score: (0.801024939470616, 0.45385173908025694), Time: 17.30600s\n",
      "(array([0.99632316, 0.27132052]), array([0.91194117, 0.90691313]), array([0.95226651, 0.4176831 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98811122, 0.19651405]), array([0.91098117, 0.66514333]), array([0.94797991, 0.30339208]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 074, Loss: 0.33723, Train Score: (0.9094271481097933, 0.5907408311556407), Val Score: (0.7880622486899554, 0.4361353745155554), Time: 17.26000s\n",
      "(array([0.99672238, 0.24496429]), array([0.89766427, 0.91835212]), array([0.94460344, 0.38676232]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98933819, 0.18865612]), array([0.90098593, 0.70336518]), array([0.9430973, 0.2975134]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 075, Loss: 0.34896, Train Score: (0.9080081966084923, 0.5830826462529418), Val Score: (0.8021755549735677, 0.4507116072680909), Time: 17.25400s\n",
      "(array([0.99671802, 0.30283678]), array([0.92377265, 0.91586538]), array([0.95886001, 0.455169  ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98879093, 0.23409742]), array([0.92729993, 0.67885334]), array([0.95705875, 0.34814105]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 076, Loss: 0.34575, Train Score: (0.9198190165766158, 0.6108189069992755), Val Score: (0.8030766348089079, 0.46156479314725446), Time: 17.25000s\n",
      "(array([0.99644156, 0.31869219]), array([0.92980826, 0.9081565 ]), array([0.96197241, 0.47181431]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98836757, 0.24672119]), array([0.93360985, 0.66431242]), array([0.96020868, 0.35981098]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 077, Loss: 0.34636, Train Score: (0.9189823807658182, 0.6150266565792727), Val Score: (0.7989611338769661, 0.46083665291097936), Time: 17.20500s\n",
      "(array([0.9960256 , 0.30712078]), array([0.92677847, 0.8977122 ]), array([0.96015511, 0.45766687]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98811692, 0.23419031]), array([0.92951656, 0.65849605]), array([0.95792136, 0.34550409]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 078, Loss: 0.33917, Train Score: (0.9122453349859827, 0.6042010162640267), Val Score: (0.7940063049599589, 0.4517552052198394), Time: 17.32400s\n",
      "(array([0.99637908, 0.33558489]), array([0.93514861, 0.90600133]), array([0.96479333, 0.48976117]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9875644 , 0.25371165]), array([0.93847828, 0.63896967]), array([0.96239584, 0.36320699]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 079, Loss: 0.34103, Train Score: (0.9205749695138195, 0.6224330233992285), Val Score: (0.7887239737208306, 0.452062130705395), Time: 17.18900s\n",
      "(array([0.99655579, 0.35397659]), array([0.93994654, 0.91014589]), array([0.96742374, 0.50971381]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98727728, 0.26665492]), array([0.9434147, 0.6285833]), array([0.96484774, 0.37445861]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 080, Loss: 0.34485, Train Score: (0.9250462125792397, 0.6336288484443712), Val Score: (0.7859989995974265, 0.45350517888793707), Time: 17.29300s\n",
      "(array([0.99637518, 0.36221308]), array([0.94237697, 0.90517241]), array([0.96862409, 0.51738842]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9874718 , 0.27906977]), array([0.94646087, 0.6331533 ]), array([0.9665315 , 0.38739197]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 081, Loss: 0.31631, Train Score: (0.9237746894819763, 0.6353471225087195), Val Score: (0.7898070859202984, 0.46192518241136704), Time: 17.22800s\n",
      "(array([0.99645937, 0.37196656]), array([0.94462459, 0.9071618 ]), array([0.96984988, 0.52759967]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98757509, 0.28555431]), array([0.94794316, 0.63564603]), array([0.96735337, 0.39407598]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 082, Loss: 0.31983, Train Score: (0.9258931954501423, 0.6411838470658153), Val Score: (0.791794594362802, 0.46637431528308276), Time: 17.26100s\n",
      "(array([0.99722839, 0.36368659]), array([0.94132208, 0.92763594]), array([0.96846909, 0.52251663]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98744218, 0.27834674]), array([0.94633848, 0.63232239]), array([0.96645349, 0.38653968]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 083, Loss: 0.29725, Train Score: (0.9344790114413063, 0.6469237377179081), Val Score: (0.7893304356480042, 0.46116138405946094), Time: 17.23500s\n",
      "(array([0.99769389, 0.32174653]), array([0.92830985, 0.94064987]), array([0.96175209, 0.4794862 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98812834, 0.24230828]), array([0.93268512, 0.65766514]), array([0.95960656, 0.3541387 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 084, Loss: 0.28726, Train Score: (0.9344798577773151, 0.6322336273078075), Val Score: (0.7951751296315688, 0.45541190509372653), Time: 17.23900s\n",
      "(array([0.99707544, 0.30739353]), array([0.92465072, 0.92498342]), array([0.95949833, 0.46143985]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98840032, 0.22512942]), array([0.92468892, 0.66846697]), array([0.95548373, 0.33682227]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 085, Loss: 0.29429, Train Score: (0.9248170706446956, 0.6174972259899005), Val Score: (0.7965779474877068, 0.4520522077725094), Time: 17.20800s\n",
      "(array([0.99673808, 0.3502443 ]), array([0.93862793, 0.91503647]), array([0.96681061, 0.50658529]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9878535 , 0.26111018]), array([0.94008295, 0.64686332]), array([0.9633764 , 0.37204301]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 086, Loss: 0.31581, Train Score: (0.9268322018984285, 0.6341226733830342), Val Score: (0.7934731345129028, 0.45958312356690595), Time: 17.26400s\n",
      "(array([0.99728824, 0.31835461]), array([0.92799218, 0.93020557]), array([0.96139314, 0.47436277]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98840914, 0.24372814]), array([0.93235874, 0.66597424]), array([0.95956613, 0.35685663]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 087, Loss: 0.29912, Train Score: (0.9290988772804104, 0.6254977329159229), Val Score: (0.7991664912652348, 0.46014470613343184), Time: 17.19600s\n",
      "(array([0.99745276, 0.35551067]), array([0.93880474, 0.933687  ]), array([0.96724055, 0.51494925]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98762193, 0.26452389]), array([0.94181002, 0.63938513]), array([0.9641721 , 0.37422492]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 088, Loss: 0.28465, Train Score: (0.936245873616377, 0.6457557405271248), Val Score: (0.7905975745760231, 0.4576693967201166), Time: 17.18500s\n",
      "(array([0.99798047, 0.33831405]), array([0.93298191, 0.94777851]), array([0.96438722, 0.49863719]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98789773, 0.25197485]), array([0.9369008 , 0.64935604]), array([0.96172369, 0.3630662 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 089, Loss: 0.27015, Train Score: (0.9403802098666084, 0.6439573459726724), Val Score: (0.7931284202043353, 0.45622232022382064), Time: 17.31900s\n",
      "(array([0.99719013, 0.35896613]), array([0.9401683 , 0.92672414]), array([0.96784006, 0.51748478]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98723786, 0.26697313]), array([0.94361868, 0.62733693]), array([0.96493558, 0.37455042]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 090, Loss: 0.26811, Train Score: (0.9334462199337927, 0.6441235123901166), Val Score: (0.7854778094613044, 0.45306085277815994), Time: 17.21100s\n",
      "(array([0.997981 , 0.3441705]), array([0.93471108, 0.94769562]), array([0.96531041, 0.50495771]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98796872, 0.25587851]), array([0.93802951, 0.65101786]), array([0.96235168, 0.36736608]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 091, Loss: 0.26186, Train Score: (0.9412033495120519, 0.6468455731251961), Val Score: (0.7945236871594767, 0.45897872413151924), Time: 17.29700s\n",
      "(array([0.99730414, 0.35955632]), array([0.94012934, 0.92970822]), array([0.96787311, 0.51856304]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98663599, 0.2651474 ]), array([0.9447474 , 0.60905692]), array([0.96523745, 0.36945565]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 092, Loss: 0.27521, Train Score: (0.9349187829833067, 0.6458585934680597), Val Score: (0.7769021582610656, 0.44329767859109165), Time: 17.21800s\n",
      "(array([0.99713603, 0.35833975]), array([0.94009638, 0.92531499]), array([0.96777647, 0.51661422]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98710632, 0.26449339]), array([0.94323791, 0.62359784]), array([0.96467365, 0.37144271]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 093, Loss: 0.30267, Train Score: (0.9327056823847213, 0.6431303346719123), Val Score: (0.7834178767764709, 0.45001069446506753), Time: 17.19900s\n",
      "(array([0.99650792, 0.33785032]), array([0.93556817, 0.90931698]), array([0.96507699, 0.4926573 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98773772, 0.24967825]), array([0.93657442, 0.64478604]), array([0.96147591, 0.35996753]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 094, Loss: 0.30472, Train Score: (0.9224425725023243, 0.6251657177195573), Val Score: (0.790680230529318, 0.4528614412381321), Time: 17.28900s\n",
      "(array([0.99704638, 0.33169599]), array([0.93272418, 0.92357427]), array([0.9638133, 0.4880955]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98800531, 0.23943448]), array([0.93196437, 0.6543415 ]), array([0.95916696, 0.35058431]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 095, Loss: 0.29367, Train Score: (0.9281492241884478, 0.6289684636105083), Val Score: (0.793152937327324, 0.4523658559420755), Time: 17.17200s\n",
      "(array([0.9974903 , 0.37355427]), array([0.94335093, 0.93435013]), array([0.96966551, 0.53372476]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98745359, 0.27024632]), array([0.94399946, 0.63356876]), array([0.9652377 , 0.37888199]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 096, Loss: 0.26900, Train Score: (0.9388505336685351, 0.6550975359271606), Val Score: (0.7887841069155602, 0.45771460361897953), Time: 17.49321s\n",
      "(array([0.99722511, 0.33983913]), array([0.93482196, 0.9280504 ]), array([0.96501575, 0.4975005 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98782985, 0.25528775]), array([0.93823349, 0.64686332]), array([0.96239311, 0.36609452]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 097, Loss: 0.26341, Train Score: (0.9314361781230154, 0.6352000040739115), Val Score: (0.7925484047923615, 0.4566719098922196), Time: 17.44546s\n",
      "(array([0.99830907, 0.31660814]), array([0.92534598, 0.95664788]), array([0.96044381, 0.47576057]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98847793, 0.23214286]), array([0.92749031, 0.66971334]), array([0.95701346, 0.34477596]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 098, Loss: 0.25205, Train Score: (0.9409969309665334, 0.637384336924993), Val Score: (0.7986018234197083, 0.45616235434594415), Time: 17.33400s\n",
      "(array([0.99772909, 0.38360889]), array([0.9453648 , 0.94048408]), array([0.97084137, 0.54494369]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98712209, 0.27968633]), array([0.94753519, 0.62235147]), array([0.96692363, 0.38593327]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 099, Loss: 0.26226, Train Score: (0.9429244444589825, 0.6630848075689062), Val Score: (0.7849433310953703, 0.4570037345032455), Time: 17.19100s\n",
      "(array([0.99702737, 0.3809899 ]), array([0.9458413 , 0.92199934]), array([0.97076007, 0.53917933]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98760114, 0.28523552]), array([0.94779357, 0.63647694]), array([0.96728797, 0.3939316 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 100, Loss: 0.25182, Train Score: (0.9339203183873637, 0.6528554260337365), Val Score: (0.7921352549703107, 0.4666172086626543), Time: 17.16200s\n",
      "(array([0.99671381, 0.3616805 ]), array([0.94167271, 0.91412467]), array([0.96841181, 0.51829397]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98805843, 0.2720652 ]), array([0.94291154, 0.65184877]), array([0.96495721, 0.38390017]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 101, Loss: 0.26271, Train Score: (0.9278986893537724, 0.6394007744950249), Val Score: (0.7973801565655169, 0.46747435499378637), Time: 17.29900s\n",
      "(array([0.99834231, 0.34707067]), array([0.93490587, 0.95706233]), array([0.96558331, 0.50940857]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98856207, 0.25374075]), array([0.9355681 , 0.66929788]), array([0.96133531, 0.36797624]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 102, Loss: 0.27244, Train Score: (0.9459841019037403, 0.6528155985937859), Val Score: (0.8024329890022667, 0.4667601555720555), Time: 17.25100s\n",
      "(array([0.99808763, 0.31702869]), array([0.92593636, 0.95092838]), array([0.96065915, 0.47552332]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98855367, 0.22806029]), array([0.92547766, 0.67262152]), array([0.95597634, 0.34062697]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 103, Loss: 0.24650, Train Score: (0.9384323706473459, 0.634834643450856), Val Score: (0.7990495921312889, 0.455529075292516), Time: 17.24600s\n",
      "(array([0.9984017 , 0.34478133]), array([0.93413568, 0.95863727]), array([0.96520012, 0.50715899]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98826537, 0.25162209]), array([0.93569049, 0.66057333]), array([0.96125959, 0.36442815]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 104, Loss: 0.24072, Train Score: (0.9463864761751827, 0.6524309163510638), Val Score: (0.7981319076584414, 0.4614768150550863), Time: 17.23900s\n",
      "(array([0.99832534, 0.35776517]), array([0.93792368, 0.9564821 ]), array([0.96718239, 0.52074825]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98751644, 0.25524126]), array([0.93913103, 0.63730785]), array([0.96271616, 0.36450042]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 105, Loss: 0.22575, Train Score: (0.9472028861203573, 0.6578828514000721), Val Score: (0.7882194390700342, 0.45202236586588895), Time: 17.27200s\n",
      "(array([0.99814923, 0.32267123]), array([0.92771947, 0.95242042]), array([0.96164653, 0.48203386]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98824159, 0.23441176]), array([0.92920378, 0.66223515]), array([0.9578138 , 0.34625828]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 106, Loss: 0.24667, Train Score: (0.9400699486004814, 0.638375909138925), Val Score: (0.7957194639995894, 0.4536762253148042), Time: 17.21000s\n",
      "(array([0.99904348, 0.29083183]), array([0.91397601, 0.97579576]), array([0.95461837, 0.44810719]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98924352, 0.21469796]), array([0.91673353, 0.69547154]), array([0.95160926, 0.32810662]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 107, Loss: 0.22605, Train Score: (0.944885884673008, 0.6337360636218012), Val Score: (0.8061025347948089, 0.4599108025062755), Time: 17.22400s\n",
      "(array([0.99888524, 0.26993371]), array([0.90494956, 0.97206565]), array([0.94959999, 0.42253369]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98954481, 0.19786221]), array([0.90611274, 0.70751973]), array([0.94599276, 0.30924278]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 108, Loss: 0.23117, Train Score: (0.9385076066146685, 0.6214870251630629), Val Score: (0.8068162347704783, 0.45732608591828405), Time: 17.19300s\n",
      "(array([0.99872192, 0.27688586]), array([0.90861768, 0.9678382 ]), array([0.9515415 , 0.43058654]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98956396, 0.20741825]), array([0.91166111, 0.70627337]), array([0.9490165 , 0.32066396]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 109, Loss: 0.23636, Train Score: (0.9382279393891978, 0.6229231292149179), Val Score: (0.8089672415473906, 0.4615006792617178), Time: 17.24300s\n",
      "(array([0.99907121, 0.29468418]), array([0.9155044 , 0.97645889]), array([0.95546405, 0.45273737]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98884115, 0.21252421]), array([0.9170599, 0.6838388]), array([0.95159879, 0.32427108]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 110, Loss: 0.25166, Train Score: (0.9459816411451538, 0.6359822331501508), Val Score: (0.8004493534685797, 0.4531919090042392), Time: 17.25100s\n",
      "(array([0.9990437 , 0.35557772]), array([0.9361016 , 0.97521552]), array([0.96654903, 0.52114017]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98795715, 0.25975104]), array([0.93934861, 0.65018695]), array([0.9630399 , 0.37120493]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 111, Loss: 0.25509, Train Score: (0.9556585608719079, 0.6658290116414676), Val Score: (0.7947677821105454, 0.46051270043589987), Time: 17.19600s\n",
      "(array([0.99854692, 0.39766964]), array([0.94732773, 0.96187003]), array([0.97226323, 0.56270003]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98694539, 0.28326016]), array([0.94893588, 0.61653511]), array([0.96756749, 0.38817682]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 112, Loss: 0.24193, Train Score: (0.9545988768948764, 0.6804350521664139), Val Score: (0.7827354934070295, 0.4559746411834968), Time: 17.13200s\n",
      "(array([0.99866153, 0.38214344]), array([0.94359068, 0.96501989]), array([0.97034536, 0.54748525]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98681687, 0.26653451]), array([0.94465221, 0.61445783]), array([0.9652743 , 0.37179487]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 113, Loss: 0.24883, Train Score: (0.9543052874793218, 0.6741919361317402), Val Score: (0.7795550188788063, 0.4466060970201319), Time: 17.19000s\n",
      "(array([0.99897534, 0.38463554]), array([0.94370756, 0.97322613]), array([0.97055528, 0.55136303]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98702258, 0.27086357]), array([0.94534575, 0.6202742 ]), array([0.96573473, 0.37706781]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 114, Loss: 0.22460, Train Score: (0.9584668423626106, 0.6793979364843957), Val Score: (0.7828099769859951, 0.45158663570902696), Time: 17.27500s\n",
      "(array([0.99853184, 0.40917269]), array([0.9498121 , 0.96137268]), array([0.97356284, 0.57403054]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98627744, 0.28867849]), array([0.95198205, 0.5953469 ]), array([0.96882633, 0.38882106]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 115, Loss: 0.21970, Train Score: (0.9555923889222815, 0.6859465836455801), Val Score: (0.7736644771125355, 0.4484254836839162), Time: 17.22500s\n",
      "(array([0.99886836, 0.38662483]), array([0.94433989, 0.97040782]), array([0.97083906, 0.55294729]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98762299, 0.28365385]), array([0.9473176 , 0.63730785]), array([0.96705051, 0.39257837]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 116, Loss: 0.21397, Train Score: (0.9573738566658809, 0.679032598884573), Val Score: (0.792312727980077, 0.46622865666327795), Time: 17.16100s\n",
      "(array([0.99873223, 0.39608096]), array([0.94670738, 0.96676061]), array([0.97202418, 0.56193688]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98682631, 0.28794686]), array([0.95043177, 0.61238056]), array([0.96828717, 0.39170874]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 117, Loss: 0.21629, Train Score: (0.9567339968338696, 0.6820006846908314), Val Score: (0.7814061619476455, 0.45630655652184476), Time: 17.29600s\n",
      "(array([0.99914687, 0.37314944]), array([0.94061483, 0.97778515]), array([0.96899775, 0.54015936]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98704107, 0.26510721]), array([0.94360509, 0.62152057]), array([0.96483446, 0.37167702]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 118, Loss: 0.22336, Train Score: (0.959199987699486, 0.6758548546738983), Val Score: (0.7825628255160793, 0.44931188721968296), Time: 17.13800s\n",
      "(array([0.99848409, 0.36499937]), array([0.93958392, 0.96054377]), array([0.96813898, 0.52898749]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98639932, 0.24190065]), array([0.93794792, 0.60490237]), array([0.96156366, 0.34559696]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 119, Loss: 0.20195, Train Score: (0.9500638433953322, 0.6634599269492898), Val Score: (0.7714251420257245, 0.42966286537227616), Time: 17.27900s\n",
      "(array([0.99874603, 0.37947967]), array([0.9428175 , 0.96725796]), array([0.96997623, 0.54510207]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98669677, 0.26688453]), array([0.94508737, 0.61071874]), array([0.96544395, 0.37144662]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 120, Loss: 0.20722, Train Score: (0.9550377283228244, 0.6739400381594152), Val Score: (0.777903055188329, 0.4449708160476863), Time: 17.26000s\n",
      "(array([0.99831405, 0.36746527]), array([0.94050095, 0.95606764]), array([0.96854554, 0.53088465]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98624423, 0.24330244]), array([0.93892704, 0.59991691]), array([0.96200415, 0.34619995]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 121, Loss: 0.21651, Train Score: (0.9482842946261, 0.6625329060520111), Val Score: (0.7694219752801071, 0.427950041090068), Time: 17.22900s\n",
      "(array([0.99804595, 0.36909636]), array([0.94135205, 0.94902188]), array([0.96887034, 0.53148574]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98738526, 0.26304874]), array([0.94201401, 0.63232239]), array([0.96416616, 0.37153668]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 122, Loss: 0.24975, Train Score: (0.94518696641036, 0.6599484927249686), Val Score: (0.7871681999779151, 0.4535123808782079), Time: 17.26000s\n",
      "(array([0.9986687 , 0.38467129]), array([0.94418106, 0.96518568]), array([0.97066082, 0.55010157]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98750974, 0.28627745]), array([0.94829673, 0.63356876]), array([0.96750607, 0.39436255]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 123, Loss: 0.23730, Train Score: (0.9546833664174286, 0.675535859321417), Val Score: (0.7909327436191708, 0.4657301694186244), Time: 17.17600s\n",
      "(array([0.99877461, 0.36071649]), array([0.93796563, 0.96816976]), array([0.96741549, 0.52560526]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98679119, 0.2506342 ]), array([0.93974298, 0.6157042 ]), array([0.9626926, 0.35625  ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 124, Loss: 0.22435, Train Score: (0.9530676968170857, 0.664998441000987), Val Score: (0.7777235878141395, 0.43925937004741866), Time: 17.27300s\n",
      "(array([0.99894562, 0.36871877]), array([0.93979969, 0.972563  ]), array([0.96847046, 0.53471573]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98689347, 0.25869868]), array([0.9420548 , 0.61778147]), array([0.96395299, 0.36468424]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 125, Loss: 0.21721, Train Score: (0.9561813446367112, 0.6711195535442567), Val Score: (0.7799181372726682, 0.44429732847602715), Time: 17.25200s\n",
      "(array([0.99843425, 0.38251727]), array([0.94402822, 0.95905172]), array([0.97046931, 0.5469027 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98675637, 0.27555223]), array([0.947372  , 0.61154965]), array([0.9666632 , 0.37991999]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 126, Loss: 0.20533, Train Score: (0.9515399711415667, 0.6714988882985855), Val Score: (0.779460823295668, 0.4497069510467135), Time: 17.24400s\n",
      "(array([0.99862032, 0.38177938]), array([0.94356671, 0.96394231]), array([0.97031323, 0.5469382 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98675159, 0.27062282]), array([0.9460121, 0.6119651]), array([0.96595248, 0.37528662]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 127, Loss: 0.22542, Train Score: (0.9537545070584552, 0.6734899124898286), Val Score: (0.778988602433311, 0.4474433898706209), Time: 17.25100s\n",
      "(array([0.99756942, 0.38464158]), array([0.94584729, 0.93625663]), array([0.97102009, 0.54527022]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98517314, 0.26155624]), array([0.94786156, 0.56418779]), array([0.96615726, 0.35741545]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 128, Loss: 0.21222, Train Score: (0.9410519624315724, 0.6615611809048999), Val Score: (0.7560246740732539, 0.41977859960309705), Time: 17.23400s\n",
      "(array([0.99715673, 0.42259176]), array([0.95431933, 0.92473475]), array([0.97526786, 0.58008996]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9851101 , 0.30382613]), array([0.95818318, 0.55754051]), array([0.97146009, 0.3933177 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 129, Loss: 0.21837, Train Score: (0.9395270390796563, 0.6749763439160553), Val Score: (0.7578618424667362, 0.4376952467497725), Time: 17.20600s\n",
      "(array([0.99839107, 0.40159889]), array([0.94840659, 0.95772546]), array([0.97275714, 0.56590096]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98634817, 0.28185555]), array([0.95010539, 0.59825509]), array([0.96788762, 0.38318254]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 130, Loss: 0.23422, Train Score: (0.9530660250115855, 0.6803997030755955), Val Score: (0.7741802406565086, 0.446422020080286), Time: 17.22500s\n",
      "(array([0.99861476, 0.46061759]), array([0.95922214, 0.96319629]), array([0.97852215, 0.62320667]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98625612, 0.3382528 ]), array([0.96219487, 0.59036145]), array([0.97407693, 0.43008475]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 131, Loss: 0.21357, Train Score: (0.9612092147224417, 0.7125490217967047), Val Score: (0.776278159486385, 0.47079891773903415), Time: 17.25300s\n",
      "(array([0.99856199, 0.47407347]), array([0.96142781, 0.96170424]), array([0.97964312, 0.63508225]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98604871, 0.34675228]), array([0.96403073, 0.58329871]), array([0.97491542, 0.43494424]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 132, Loss: 0.19245, Train Score: (0.9615660267047543, 0.7185569691744952), Val Score: (0.77366472287699, 0.47162922219676773), Time: 17.24100s\n",
      "(array([0.9988037 , 0.47172859]), array([0.96080147, 0.96816976]), array([0.9794341 , 0.63436889]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98620507, 0.34502924]), array([0.96344598, 0.58828417]), array([0.97469269, 0.43495623]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 133, Loss: 0.18882, Train Score: (0.9644856166578942, 0.7205044924238622), Val Score: (0.7758650746365463, 0.4731814216975629), Time: 17.47100s\n",
      "(array([0.99891928, 0.47496858]), array([0.96118507, 0.97123674]), array([0.97968896, 0.63795497]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9859919 , 0.34525277]), array([0.96389474, 0.58163689]), array([0.97481812, 0.43330238]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 134, Loss: 0.17913, Train Score: (0.9662109018002455, 0.7236044683911927), Val Score: (0.7727658181983155, 0.47007489315737855), Time: 17.28700s\n",
      "(array([0.99903461, 0.47712604]), array([0.96139784, 0.97430371]), array([0.97985495, 0.64056241]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98588769, 0.34635481]), array([0.96427552, 0.57831325]), array([0.97496184, 0.43323996]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 135, Loss: 0.17822, Train Score: (0.9678507773059921, 0.7261631776526611), Val Score: (0.7712943840364519, 0.4690167653795711), Time: 17.30600s\n",
      "(array([0.99905361, 0.47939342]), array([0.96172749, 0.97480106]), array([0.98003527, 0.64271075]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98578535, 0.34826371]), array([0.96477868, 0.57498961]), array([0.9751689 , 0.43378781]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 136, Loss: 0.17516, Train Score: (0.9682642766605452, 0.7275368647947088), Val Score: (0.7698841452237415, 0.46836206721854534), Time: 17.26700s\n",
      "(array([0.99911252, 0.47850991]), array([0.9615297 , 0.97637599]), array([0.97996091, 0.64225736]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9858869 , 0.34601044]), array([0.96422112, 0.57831325]), array([0.97493366, 0.43297045]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 137, Loss: 0.17232, Train Score: (0.9689528481353467, 0.727855100979), Val Score: (0.7712671861034947, 0.4688445780494043), Time: 17.22600s\n",
      "(array([0.99919564, 0.47229668]), array([0.96046882, 0.97861406]), array([0.97944957, 0.63711179]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98597019, 0.34163614]), array([0.96333719, 0.58122144]), array([0.97452229, 0.43032913]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 138, Loss: 0.17042, Train Score: (0.9695414411698312, 0.7258284689305325), Val Score: (0.7722793119239348, 0.4680654333095321), Time: 17.34800s\n",
      "(array([0.99922118, 0.47733333]), array([0.96123302, 0.97927719]), array([0.97985905, 0.64182105]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98584342, 0.34449405]), array([0.96405793, 0.57706689]), array([0.97482897, 0.43143345]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 139, Loss: 0.16741, Train Score: (0.9702551018992728, 0.7286667937306167), Val Score: (0.7705624099199121, 0.46748295140506696), Time: 17.31200s\n",
      "(array([0.99919126, 0.48654219]), array([0.9626685 , 0.97844828]), array([0.98058992, 0.64991053]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98571369, 0.35197957]), array([0.96549942, 0.57249688]), array([0.97550185, 0.43593799]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 140, Loss: 0.16734, Train Score: (0.9705583862962641, 0.7328712256710949), Val Score: (0.7689981530660005, 0.4690131320963679), Time: 17.31400s\n",
      "(array([0.9992593 , 0.48399771]), array([0.96221598, 0.98027188]), array([0.98038785, 0.64803551]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98573413, 0.34919028]), array([0.96502346, 0.57332779]), array([0.97526885, 0.43403051]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 141, Loss: 0.16390, Train Score: (0.9712439293935239, 0.7324789750207044), Val Score: (0.7691756260757668, 0.46802077788962176), Time: 17.31100s\n",
      "(array([0.99926621, 0.49013758]), array([0.96312701, 0.98043767]), array([0.98086384, 0.65355288]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98558606, 0.35449598]), array([0.96612497, 0.56834233]), array([0.97575849, 0.4366422 ]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 142, Loss: 0.16184, Train Score: (0.9717823387020987, 0.7356289082792159), Val Score: (0.7672336546793029, 0.4682599060218116), Time: 17.31500s\n",
      "(array([0.99928504, 0.4920173 ]), array([0.96338474, 0.98093501]), array([0.98100655, 0.65533282]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9856604 , 0.35811163]), array([0.96653294, 0.57041961]), array([0.97600297, 0.43999359]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 143, Loss: 0.16089, Train Score: (0.9721598761043972, 0.7368087648283201), Val Score: (0.7684762764843333, 0.4710734481418343), Time: 17.32700s\n",
      "(array([0.9993006 , 0.49232753]), array([0.96341471, 0.98134947]), array([0.98102959, 0.65570048]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98558159, 0.35860441]), array([0.96675053, 0.56792688]), array([0.97607524, 0.43962052]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 144, Loss: 0.15858, Train Score: (0.9723820883678808, 0.7371638769890684), Val Score: (0.7673387034467392, 0.4701129743922045), Time: 17.30100s\n",
      "(array([0.9992919 , 0.49814815]), array([0.96426581, 0.9811008 ]), array([0.98146646, 0.66078607]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98546508, 0.36011668]), array([0.96718569, 0.56418779]), array([0.97623983, 0.43962447]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 145, Loss: 0.15808, Train Score: (0.9726833012661994, 0.7399541899563966), Val Score: (0.7656867397562621, 0.4690588193810718), Time: 17.35900s\n",
      "(array([0.99929838, 0.50078261]), array([0.96463442, 0.98126658]), array([0.98166048, 0.66313755]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98548416, 0.36288385]), array([0.96755287, 0.56460324]), array([0.9764362 , 0.44180754]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 146, Loss: 0.15785, Train Score: (0.9729504975181881, 0.7413514173743773), Val Score: (0.7660780532652929, 0.4706435454712069), Time: 17.29500s\n",
      "(array([0.99930184, 0.50432375]), array([0.96512889, 0.98134947]), array([0.98191813, 0.66625397]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98531366, 0.36398053]), array([0.96801523, 0.55920233]), array([0.97658785, 0.44095004]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 147, Loss: 0.15473, Train Score: (0.97323918156328, 0.7431619886919534), Val Score: (0.7636087786950129, 0.4685770225512081), Time: 17.29300s\n",
      "(array([0.9994098 , 0.49836313]), array([0.9641819 , 0.98425066]), array([0.98147984, 0.66168849]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98549279, 0.36064704]), array([0.96721289, 0.5650187 ]), array([0.97626728, 0.44027193]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 148, Loss: 0.15438, Train Score: (0.9742162793422384, 0.7415816629246836), Val Score: (0.7661157936458816, 0.4697262880096853), Time: 17.30800s\n",
      "(array([0.99934247, 0.50797188]), array([0.9655964 , 0.98242706]), array([0.98217965, 0.66968019]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98535964, 0.36697497]), array([0.96835521, 0.56044869]), array([0.97678342, 0.44353115]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 149, Loss: 0.15306, Train Score: (0.9740117273563828, 0.7455060498040613), Val Score: (0.764401948160706, 0.47067767441013), Time: 17.42300s\n",
      "(array([0.99944455, 0.50595998]), array([0.9652218 , 0.98516247]), array([0.98203511, 0.6685605 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98530043, 0.36400541]), array([0.96804243, 0.55878687]), array([0.97659519, 0.44083907]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 150, Loss: 0.15028, Train Score: (0.9751921310920156, 0.7458200824635269), Val Score: (0.7634146501999208, 0.4683883204134497), Time: 17.94500s\n",
      "(array([0.9994078, 0.5112824]), array([0.96598898, 0.98416777]), array([0.98241427, 0.67295811]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98533663, 0.36873802]), array([0.96864078, 0.55961778]), array([0.97691738, 0.44455446]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 151, Loss: 0.15136, Train Score: (0.975078377769291, 0.7480012993850138), Val Score: (0.7641292823855899, 0.47115691280383437), Time: 17.62600s\n",
      "(array([0.99939238, 0.51197101]), array([0.96609687, 0.98375332]), array([0.98246261, 0.67345723]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98528619, 0.3700744 ]), array([0.96891276, 0.55795596]), array([0.97703088, 0.44499669]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 152, Loss: 0.14999, Train Score: (0.9749250925809616, 0.7481456049889146), Val Score: (0.7634343622040937, 0.47102052740498984), Time: 17.31200s\n",
      "(array([0.99942657, 0.51355324]), array([0.96627968, 0.98466512]), array([0.98257365, 0.67503907]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98523455, 0.37081141]), array([0.96910315, 0.55629414]), array([0.97710227, 0.44499834]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 153, Loss: 0.14738, Train Score: (0.9754723977330394, 0.7493767141475082), Val Score: (0.7626986451231617, 0.4705844579068696), Time: 17.25300s\n",
      "(array([0.99942979, 0.51515546]), array([0.96649245, 0.98474801]), array([0.9826852 , 0.67644128]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98527847, 0.37288136]), array([0.96930713, 0.55754051]), array([0.97722755, 0.44688645]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 154, Loss: 0.14662, Train Score: (0.9756202307984678, 0.7502178221518238), Val Score: (0.7634238197564622, 0.47222286155083004), Time: 17.15700s\n",
      "(array([0.99945174, 0.51887904]), array([0.96696895, 0.98532825]), array([0.98294206, 0.67978155]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98522038, 0.37715092]), array([0.96997348, 0.55546323]), array([0.97753748, 0.44926075]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 155, Loss: 0.14655, Train Score: (0.976148598095549, 0.7523596115466797), Val Score: (0.7627183571273345, 0.47335192452887087), Time: 17.14500s\n",
      "(array([0.99943319, 0.5190703 ]), array([0.9670109, 0.9848309]), array([0.98295476, 0.6798272 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98517096, 0.37220982]), array([0.96940233, 0.55421687]), array([0.97722303, 0.44533467]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 156, Loss: 0.14554, Train Score: (0.9759209021609779, 0.752215240898443), Val Score: (0.7618095964465738, 0.4702779463822796), Time: 17.17400s\n",
      "(array([0.99936287, 0.52873768]), array([0.96832651, 0.9829244 ]), array([0.98359992, 0.68759966]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98502932, 0.38130949]), array([0.97083022, 0.54923141]), array([0.97787823, 0.45011917]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 157, Loss: 0.14342, Train Score: (0.9756254568674301, 0.7561289458296911), Val Score: (0.7600308126478524, 0.4724140585289754), Time: 17.08500s\n",
      "(array([0.99947661, 0.52047782]), array([0.96715775, 0.98599138]), array([0.98305162, 0.6813105 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98528518, 0.37633202]), array([0.9697559 , 0.55754051]), array([0.97745886, 0.44935543]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 158, Loss: 0.14361, Train Score: (0.9765745632069545, 0.7534789937450596), Val Score: (0.7636482027033582, 0.47394819592348325), Time: 16.98800s\n",
      "(array([0.99943071, 0.52699286]), array([0.96804481, 0.98474801]), array([0.98348742, 0.6865663 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98508348, 0.38191244]), array([0.97081662, 0.55089323]), array([0.97789802, 0.45109713]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 159, Loss: 0.14292, Train Score: (0.9763964096012943, 0.756136522565778), Val Score: (0.7608549230108947, 0.4735201089494162), Time: 17.47400s\n",
      "(array([0.9994613 , 0.52256845]), array([0.96744544, 0.98557692]), array([0.9831928 , 0.68299968]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98518017, 0.37694264]), array([0.97001428, 0.55421687]), array([0.97753841, 0.44870501]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 160, Loss: 0.14251, Train Score: (0.9765111828992619, 0.7543243146923877), Val Score: (0.762115573192341, 0.4726443552497967), Time: 17.24300s\n",
      "(array([0.99947709, 0.52726064]), array([0.96803881, 0.98599138]), array([0.98350678, 0.68709566]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98515002, 0.38203215]), array([0.97072143, 0.5529705 ]), array([0.9778825 , 0.45187574]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 161, Loss: 0.14118, Train Score: (0.9770150971220724, 0.7568704050441665), Val Score: (0.761845963936072, 0.4745856786779786), Time: 17.48500s\n",
      "(array([0.99948027, 0.52861713]), array([0.96820963, 0.98607427]), array([0.98359648, 0.6882666 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9851117 , 0.38281926]), array([0.97088461, 0.55172414]), array([0.97794641, 0.45200817]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 162, Loss: 0.14046, Train Score: (0.9771419523820191, 0.7575886527527761), Val Score: (0.761304375350232, 0.47437580286535225), Time: 16.92900s\n",
      "(array([0.99950787, 0.52532874]), array([0.96776311, 0.98682029]), array([0.98337937, 0.6856534 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98525066, 0.37910532]), array([0.97017747, 0.55629414]), array([0.97765597, 0.45091766]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 163, Loss: 0.13807, Train Score: (0.9772916992051852, 0.7563044528892762), Val Score: (0.7632358042990642, 0.47473141449760636), Time: 17.54300s\n",
      "(array([0.99956646, 0.52238675]), array([0.96732857, 0.98839523]), array([0.98318332, 0.68351963]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98519214, 0.37626832]), array([0.96990549, 0.55463232]), array([0.97748905, 0.44836272]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 164, Loss: 0.13675, Train Score: (0.9778618959204821, 0.7555934471305776), Val Score: (0.7622689047879974, 0.47250833924777746), Time: 16.73200s\n",
      "(array([0.99955462, 0.53147851]), array([0.96850932, 0.98806366]), array([0.98378711, 0.69117477]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98503345, 0.3835219 ]), array([0.9711022 , 0.54923141]), array([0.97801822, 0.45165699]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 165, Loss: 0.13761, Train Score: (0.9782864888099584, 0.7599793276921347), Val Score: (0.7601668023126378, 0.4735202653449665), Time: 17.48600s\n",
      "(array([0.99956683, 0.52878049]), array([0.96815569, 0.98839523]), array([0.98361055, 0.68896978]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98501283, 0.3795977 ]), array([0.97063983, 0.54881595]), array([0.97777352, 0.44878546]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 166, Loss: 0.13768, Train Score: (0.9782754583714092, 0.7587903150582511), Val Score: (0.7597278924209321, 0.4713570208780132), Time: 17.83800s\n",
      "(array([0.99964404, 0.52689832]), array([0.96784702, 0.99046751]), array([0.98348859, 0.68787059]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98508926, 0.377955  ]), array([0.97029986, 0.55130868]), array([0.97763863, 0.44846232]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 167, Loss: 0.13449, Train Score: (0.9791572622432045, 0.7588492162234712), Val Score: (0.7608042701093728, 0.47174253052880344), Time: 17.47800s\n",
      "(array([0.99955499, 0.53783333]), array([0.96930348, 0.98806366]), array([0.98419683, 0.69652613]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98498904, 0.38821797]), array([0.97175495, 0.54756959]), array([0.97832724, 0.45432609]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 168, Loss: 0.13523, Train Score: (0.9786835686994353, 0.7631567360954814), Val Score: (0.7596622676618414, 0.4750637236342305), Time: 17.93800s\n",
      "(array([0.99966581, 0.52947168]), array([0.96815869, 0.99104775]), array([0.98366002, 0.69020061]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98496614, 0.38296016]), array([0.97114299, 0.54715413]), array([0.97800572, 0.45056449]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 169, Loss: 0.13320, Train Score: (0.979603216733036, 0.7604158947569999), Val Score: (0.7591485634545037, 0.4722336777639504), Time: 17.41600s\n",
      "(array([0.99957358, 0.53893081]), array([0.96942335, 0.98856101]), array([0.98426763, 0.69756968]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98490067, 0.39064362]), array([0.97219011, 0.5446614 ]), array([0.97850412, 0.45497137]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 170, Loss: 0.13427, Train Score: (0.9789921790265793, 0.7639454775232761), Val Score: (0.7584257588945051, 0.47486854708795456), Time: 17.30900s\n",
      "(array([0.99961991, 0.5393162 ]), array([0.96943234, 0.98980438]), array([0.98429472, 0.69820202]), array([333686,  12064], dtype=int64))\n",
      "(array([0.9848821 , 0.38768867]), array([0.97186374, 0.54424595]), array([0.97832961, 0.45281714]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 171, Loss: 0.13323, Train Score: (0.9796183586207436, 0.7647381628722676), Val Score: (0.7580548438351922, 0.4731899245605843), Time: 17.36700s\n",
      "(array([0.99967197, 0.52892781]), array([0.96808377, 0.99121353]), array([0.98362433, 0.6897785 ]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98499372, 0.38354173]), array([0.97117019, 0.54798504]), array([0.97803311, 0.45124872]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 172, Loss: 0.13331, Train Score: (0.9796486476127885, 0.7602239604568557), Val Score: (0.7595776173441229, 0.4729267469472631), Time: 17.86500s\n",
      "(array([0.99967242, 0.5394262 ]), array([0.96940237, 0.99121353]), array([0.98430473, 0.69864454]), array([333686,  12064], dtype=int64))\n",
      "(array([0.98473913, 0.38915518]), array([0.97227171, 0.53967595]), array([0.97846571, 0.45221932]), array([73535,  2407], dtype=int64))\n",
      "Epoch: 173, Loss: 0.13185, Train Score: (0.980307950070788, 0.7654731538390268), Val Score: (0.7559738262550958, 0.47171060490435984), Time: 17.66600s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m201\u001B[39m):\n\u001B[0;32m      4\u001B[0m     s \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 5\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_dl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m     train_score \u001B[38;5;241m=\u001B[39m evaluate(model, train_dl)\n\u001B[0;32m      7\u001B[0m     val_score \u001B[38;5;241m=\u001B[39m evaluate(model, val_dl)\n",
      "Cell \u001B[1;32mIn[6], line 8\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, loader, criterion, optimizer)\u001B[0m\n\u001B[0;32m      6\u001B[0m data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      7\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m----> 8\u001B[0m output \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m label \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39my\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, label\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\OneDrive\\Documents\\Projects\\CxC Cyclica\\LigandGNNV2.py:35\u001B[0m, in \u001B[0;36mLigandGNNV2.forward\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m     32\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mconv(x, edge_index)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m1\u001B[39m:]:\n\u001B[1;32m---> 35\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     37\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mact(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnorm(x))\n\u001B[0;32m     38\u001B[0m x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(x, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.1\u001B[39m, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\models\\deepgcn.py:80\u001B[0m, in \u001B[0;36mDeepGCNLayer.forward\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     78\u001B[0m h \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mdropout(h, p\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, training\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mckpt_grad \u001B[38;5;129;01mand\u001B[39;00m h\u001B[38;5;241m.\u001B[39mrequires_grad:\n\u001B[1;32m---> 80\u001B[0m     h \u001B[38;5;241m=\u001B[39m checkpoint(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv, h, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     81\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     82\u001B[0m     h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv(h, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\utils\\checkpoint.py:235\u001B[0m, in \u001B[0;36mcheckpoint\u001B[1;34m(function, use_reentrant, *args, **kwargs)\u001B[0m\n\u001B[0;32m    232\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnexpected keyword arguments: \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(arg \u001B[38;5;28;01mfor\u001B[39;00m arg \u001B[38;5;129;01min\u001B[39;00m kwargs))\n\u001B[0;32m    234\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m use_reentrant:\n\u001B[1;32m--> 235\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mCheckpointFunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreserve\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    237\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _checkpoint_without_reentrant(\n\u001B[0;32m    238\u001B[0m         function,\n\u001B[0;32m    239\u001B[0m         preserve,\n\u001B[0;32m    240\u001B[0m         \u001B[38;5;241m*\u001B[39margs\n\u001B[0;32m    241\u001B[0m     )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\utils\\checkpoint.py:96\u001B[0m, in \u001B[0;36mCheckpointFunction.forward\u001B[1;34m(ctx, run_function, preserve_rng_state, *args)\u001B[0m\n\u001B[0;32m     93\u001B[0m ctx\u001B[38;5;241m.\u001B[39msave_for_backward(\u001B[38;5;241m*\u001B[39mtensor_inputs)\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m---> 96\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mrun_function\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\gen_conv.py:158\u001B[0m, in \u001B[0;36mGENConv.forward\u001B[1;34m(self, x, edge_index, edge_attr, size)\u001B[0m\n\u001B[0;32m    155\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m x[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m edge_attr\u001B[38;5;241m.\u001B[39msize(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    157\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: OptPairTensor, edge_attr: OptTensor)\u001B[39;00m\n\u001B[1;32m--> 158\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpropagate\u001B[49m\u001B[43m(\u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_attr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_attr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msize\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msize\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg_norm \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmsg_norm(x[\u001B[38;5;241m0\u001B[39m], out)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:391\u001B[0m, in \u001B[0;36mMessagePassing.propagate\u001B[1;34m(self, edge_index, size, **kwargs)\u001B[0m\n\u001B[0;32m    388\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    389\u001B[0m         aggr_kwargs \u001B[38;5;241m=\u001B[39m res[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(res, \u001B[38;5;28mtuple\u001B[39m) \u001B[38;5;28;01melse\u001B[39;00m res\n\u001B[1;32m--> 391\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maggregate(out, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39maggr_kwargs)\n\u001B[0;32m    393\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_aggregate_forward_hooks\u001B[38;5;241m.\u001B[39mvalues():\n\u001B[0;32m    394\u001B[0m     res \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, (aggr_kwargs, ), out)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\conv\\message_passing.py:514\u001B[0m, in \u001B[0;36mMessagePassing.aggregate\u001B[1;34m(self, inputs, index, ptr, dim_size)\u001B[0m\n\u001B[0;32m    501\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21maggregate\u001B[39m(\u001B[38;5;28mself\u001B[39m, inputs: Tensor, index: Tensor,\n\u001B[0;32m    502\u001B[0m               ptr: Optional[Tensor] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    503\u001B[0m               dim_size: Optional[\u001B[38;5;28mint\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m    504\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Aggregates messages from neighbors as\u001B[39;00m\n\u001B[0;32m    505\u001B[0m \u001B[38;5;124;03m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001B[39;00m\n\u001B[0;32m    506\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;124;03m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001B[39;00m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 514\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43maggr_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mptr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mptr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdim_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdim_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    515\u001B[0m \u001B[43m                            \u001B[49m\u001B[43mdim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnode_dim\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\watai\\lib\\site-packages\\torch_geometric\\nn\\aggr\\base.py:109\u001B[0m, in \u001B[0;36mAggregation.__call__\u001B[1;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001B[0m\n\u001B[0;32m    107\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m dim_size \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    108\u001B[0m         dim_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m--> 109\u001B[0m     \u001B[38;5;28;01melif\u001B[39;00m index\u001B[38;5;241m.\u001B[39mnumel() \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m dim_size \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    110\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEncountered invalid \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdim_size\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (got \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    111\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdim_size\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m but expected \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    112\u001B[0m                          \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m>= \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mint\u001B[39m(index\u001B[38;5;241m.\u001B[39mmax())\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__call__\u001B[39m(x, index, ptr, dim_size, dim, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "train_hist = []\n",
    "val_hist = []\n",
    "for epoch in range(1, 201):\n",
    "    s = time.time()\n",
    "    loss = train(model, train_dl, criterion, optimizer)\n",
    "    train_score = evaluate(model, train_dl)\n",
    "    val_score = evaluate(model, val_dl)\n",
    "    scheduler.step(loss)\n",
    "    e = time.time()\n",
    "\n",
    "    train_hist.append(train_score)\n",
    "    val_hist.append(val_score)\n",
    "\n",
    "    # print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}, Train Score: {train_score:.05f}, Val Score: {val_score:.05f}, Time: {e - s:.05f}s')\n",
    "    print(f'Epoch: {epoch:03d}, Loss: {loss:.05f}, Train Score: {train_score}, Val Score: {val_score}, Time: {e - s:.05f}s')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(val_hist)\n",
    "plt.plot(train_hist)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.9830061 , 0.36821161]), array([0.96287023, 0.56521739]), array([0.97283398, 0.44592488]), array([72691,  2783], dtype=int64))\n"
     ]
    },
    {
     "data": {
      "text/plain": "(0.7640438114161611, 0.47473050640745146)"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(model, test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "data = test_dl.dataset[4].to(device)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "pred = model(data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [1.],\n        [1.],\n        [0.],\n        [1.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], device='cuda:0', grad_fn=<RoundBackward0>)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.sigmoid(pred).round()\n",
    "out"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(30., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "458\n"
     ]
    }
   ],
   "source": [
    "print(out.sum())\n",
    "print(len(out))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(14.3125, device='cuda:0')"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.y) / data.y.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(32., device='cuda:0')"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y.sum()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "0.5806451612903225"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(data.y.detach().cpu().numpy(), out.detach().cpu().numpy())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), './models/modelV1.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
